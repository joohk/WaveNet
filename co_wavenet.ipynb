{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as mn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "raw = pd.read_csv('../arima_fc/data/canola_oil_v2.csv')\n",
    "raw.index = pd.to_datetime(raw.date).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>co</th>\n",
       "      <th>co_prod</th>\n",
       "      <th>co_domestic</th>\n",
       "      <th>ca_canola_crush</th>\n",
       "      <th>ca_co_exports</th>\n",
       "      <th>cent_ill_sbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.365</td>\n",
       "      <td>78.335</td>\n",
       "      <td>15.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-02-01</th>\n",
       "      <td>2000-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231.914</td>\n",
       "      <td>98.451</td>\n",
       "      <td>15.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-03-01</th>\n",
       "      <td>2000-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>301.705</td>\n",
       "      <td>87.800</td>\n",
       "      <td>16.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-04-01</th>\n",
       "      <td>2000-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>205.655</td>\n",
       "      <td>81.074</td>\n",
       "      <td>17.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-05-01</th>\n",
       "      <td>2000-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>265.540</td>\n",
       "      <td>61.784</td>\n",
       "      <td>16.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date  co  co_prod  co_domestic  ca_canola_crush  \\\n",
       "date                                                                \n",
       "2000-01-01  2000-01-01 NaN      NaN          NaN          273.365   \n",
       "2000-02-01  2000-02-01 NaN      NaN          NaN          231.914   \n",
       "2000-03-01  2000-03-01 NaN      NaN          NaN          301.705   \n",
       "2000-04-01  2000-04-01 NaN      NaN          NaN          205.655   \n",
       "2000-05-01  2000-05-01 NaN      NaN          NaN          265.540   \n",
       "\n",
       "            ca_co_exports  cent_ill_sbo  \n",
       "date                                     \n",
       "2000-01-01         78.335         15.56  \n",
       "2000-02-01         98.451         15.09  \n",
       "2000-03-01         87.800         16.22  \n",
       "2000-04-01         81.074         17.52  \n",
       "2000-05-01         61.784         16.75  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x16336f41988>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mn.matrix(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1800x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mn.matrix(raw[raw.co.notnull()])\n",
    "df = raw[raw.co.notnull()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>co</th>\n",
       "      <th>co_prod</th>\n",
       "      <th>co_domestic</th>\n",
       "      <th>ca_canola_crush</th>\n",
       "      <th>ca_co_exports</th>\n",
       "      <th>cent_ill_sbo</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2004-03-01</th>\n",
       "      <td>40.39</td>\n",
       "      <td>24.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>325.247</td>\n",
       "      <td>97.685</td>\n",
       "      <td>34.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-04-01</th>\n",
       "      <td>39.85</td>\n",
       "      <td>53.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>307.567</td>\n",
       "      <td>110.618</td>\n",
       "      <td>34.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-05-01</th>\n",
       "      <td>38.00</td>\n",
       "      <td>56.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>288.000</td>\n",
       "      <td>105.372</td>\n",
       "      <td>32.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-06-01</th>\n",
       "      <td>35.32</td>\n",
       "      <td>40.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>234.607</td>\n",
       "      <td>68.013</td>\n",
       "      <td>30.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-07-01</th>\n",
       "      <td>33.98</td>\n",
       "      <td>56.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>306.664</td>\n",
       "      <td>93.408</td>\n",
       "      <td>28.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               co  co_prod  co_domestic  ca_canola_crush  ca_co_exports  \\\n",
       "date                                                                      \n",
       "2004-03-01  40.39     24.0         91.0          325.247         97.685   \n",
       "2004-04-01  39.85     53.0        152.0          307.567        110.618   \n",
       "2004-05-01  38.00     56.0        108.0          288.000        105.372   \n",
       "2004-06-01  35.32     40.0         58.0          234.607         68.013   \n",
       "2004-07-01  33.98     56.0        228.0          306.664         93.408   \n",
       "\n",
       "            cent_ill_sbo  \n",
       "date                      \n",
       "2004-03-01         34.66  \n",
       "2004-04-01         34.19  \n",
       "2004-05-01         32.68  \n",
       "2004-06-01         30.08  \n",
       "2004-07-01         28.05  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop('date',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2004-03-01</th>\n",
       "      <th>2004-04-01</th>\n",
       "      <th>2004-05-01</th>\n",
       "      <th>2004-06-01</th>\n",
       "      <th>2004-07-01</th>\n",
       "      <th>2004-08-01</th>\n",
       "      <th>2004-09-01</th>\n",
       "      <th>2004-10-01</th>\n",
       "      <th>2004-11-01</th>\n",
       "      <th>2004-12-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-10-01</th>\n",
       "      <th>2019-11-01</th>\n",
       "      <th>2019-12-01</th>\n",
       "      <th>2020-01-01</th>\n",
       "      <th>2020-02-01</th>\n",
       "      <th>2020-03-01</th>\n",
       "      <th>2020-04-01</th>\n",
       "      <th>2020-05-01</th>\n",
       "      <th>2020-06-01</th>\n",
       "      <th>2020-07-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>40.390</td>\n",
       "      <td>39.850</td>\n",
       "      <td>38.000</td>\n",
       "      <td>35.320</td>\n",
       "      <td>33.980</td>\n",
       "      <td>31.950</td>\n",
       "      <td>32.150</td>\n",
       "      <td>29.850</td>\n",
       "      <td>33.930</td>\n",
       "      <td>32.170</td>\n",
       "      <td>...</td>\n",
       "      <td>38.780000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>38.440000</td>\n",
       "      <td>38.570000</td>\n",
       "      <td>35.870000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>35.280000</td>\n",
       "      <td>41.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_prod</th>\n",
       "      <td>24.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>...</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_domestic</th>\n",
       "      <td>91.000</td>\n",
       "      <td>152.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>228.000</td>\n",
       "      <td>213.000</td>\n",
       "      <td>159.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>137.000</td>\n",
       "      <td>127.000</td>\n",
       "      <td>...</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_canola_crush</th>\n",
       "      <td>325.247</td>\n",
       "      <td>307.567</td>\n",
       "      <td>288.000</td>\n",
       "      <td>234.607</td>\n",
       "      <td>306.664</td>\n",
       "      <td>259.121</td>\n",
       "      <td>223.777</td>\n",
       "      <td>288.740</td>\n",
       "      <td>274.977</td>\n",
       "      <td>283.584</td>\n",
       "      <td>...</td>\n",
       "      <td>882.301000</td>\n",
       "      <td>829.303000</td>\n",
       "      <td>899.331000</td>\n",
       "      <td>854.686000</td>\n",
       "      <td>812.633000</td>\n",
       "      <td>881.384000</td>\n",
       "      <td>845.459000</td>\n",
       "      <td>855.008000</td>\n",
       "      <td>864.559000</td>\n",
       "      <td>815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_co_exports</th>\n",
       "      <td>97.685</td>\n",
       "      <td>110.618</td>\n",
       "      <td>105.372</td>\n",
       "      <td>68.013</td>\n",
       "      <td>93.408</td>\n",
       "      <td>147.687</td>\n",
       "      <td>75.383</td>\n",
       "      <td>106.488</td>\n",
       "      <td>93.807</td>\n",
       "      <td>128.998</td>\n",
       "      <td>...</td>\n",
       "      <td>310.118426</td>\n",
       "      <td>251.207234</td>\n",
       "      <td>288.721506</td>\n",
       "      <td>311.512257</td>\n",
       "      <td>248.039262</td>\n",
       "      <td>338.876088</td>\n",
       "      <td>262.566916</td>\n",
       "      <td>340.571679</td>\n",
       "      <td>276.802196</td>\n",
       "      <td>327.788356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
       "co                   40.390      39.850      38.000      35.320      33.980   \n",
       "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
       "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
       "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
       "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
       "\n",
       "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
       "co                   31.950      32.150      29.850      33.930      32.170   \n",
       "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
       "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
       "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
       "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
       "\n",
       "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
       "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
       "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
       "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
       "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
       "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
       "\n",
       "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
       "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
       "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
       "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
       "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
       "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
       "\n",
       "date             2020-07-01  \n",
       "co                41.950000  \n",
       "co_prod          140.000000  \n",
       "co_domestic      507.000000  \n",
       "ca_canola_crush  815.000000  \n",
       "ca_co_exports    327.788356  \n",
       "\n",
       "[5 rows x 197 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_start_date = df.columns[1]\n",
    "data_end_date = df.columns[-1]\n",
    "\n",
    "pred_steps = 900\n",
    "pred_length=timedelta(pred_steps)\n",
    "print(pred_length)\n",
    "first_day = pd.to_datetime(data_start_date)\n",
    "last_day = pd.to_datetime(data_end_date)\n",
    "\n",
    "val_pred_start = last_day - pred_length + timedelta(1)\n",
    "val_pred_end = last_day\n",
    "\n",
    "train_pred_start = val_pred_start - pred_length\n",
    "train_pred_end = val_pred_start - timedelta(days=1)\n",
    "\n",
    "enc_length = train_pred_start - first_day\n",
    "\n",
    "train_enc_start = first_day\n",
    "train_enc_end = train_enc_start + enc_length - timedelta(1)\n",
    "\n",
    "val_enc_start = train_enc_start + pred_length\n",
    "val_enc_end = val_enc_start + enc_length - timedelta(1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train encoding: 2004-04-01 00:00:00 - 2015-07-28 00:00:00\n",
      "Train prediction: 2015-07-29 00:00:00 - 2018-01-13 00:00:00 \n",
      "\n",
      "Val encoding: 2006-09-18 00:00:00 - 2018-01-13 00:00:00\n",
      "Val prediction: 2018-01-14 00:00:00 - 2020-07-01 00:00:00\n",
      "\n",
      "Encoding interval: 4136\n",
      "Prediction interval: 900\n"
     ]
    }
   ],
   "source": [
    "print('Train encoding:', train_enc_start, '-', train_enc_end)\n",
    "print('Train prediction:', train_pred_start, '-', train_pred_end, '\\n')\n",
    "print('Val encoding:', val_enc_start, '-', val_enc_end)\n",
    "print('Val prediction:', val_pred_start, '-', val_pred_end)\n",
    "\n",
    "print('\\nEncoding interval:', enc_length.days)\n",
    "print('Prediction interval:', pred_length.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_index = pd.Series(index=pd.Index([pd.to_datetime(c) for c in df.columns[1:]]),\n",
    "                          data=[i for i in range(len(df.columns[1:]))])\n",
    "\n",
    "series_array = df[df.columns[1:]].values\n",
    "\n",
    "def get_time_block_series(series_array, date_to_index, start_date, end_date):\n",
    "    \n",
    "    inds = date_to_index[start_date:end_date]\n",
    "    return series_array[:,inds]\n",
    "\n",
    "def transform_series_encode(series_array):\n",
    "    \n",
    "    series_array = np.log(series_array)\n",
    "    series_mean = series_array.mean(axis=1).reshape(-1,1) \n",
    "    series_array = series_array - series_mean\n",
    "    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\n",
    "    \n",
    "    return series_array, series_mean\n",
    "\n",
    "def transform_series_decode(series_array, encode_series_mean):\n",
    "    \n",
    "    series_array = np.log(series_array)\n",
    "    series_array = series_array - encode_series_mean\n",
    "    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\n",
    "    \n",
    "    return series_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>date</th>\n",
       "      <th>2004-03-01</th>\n",
       "      <th>2004-04-01</th>\n",
       "      <th>2004-05-01</th>\n",
       "      <th>2004-06-01</th>\n",
       "      <th>2004-07-01</th>\n",
       "      <th>2004-08-01</th>\n",
       "      <th>2004-09-01</th>\n",
       "      <th>2004-10-01</th>\n",
       "      <th>2004-11-01</th>\n",
       "      <th>2004-12-01</th>\n",
       "      <th>...</th>\n",
       "      <th>2019-10-01</th>\n",
       "      <th>2019-11-01</th>\n",
       "      <th>2019-12-01</th>\n",
       "      <th>2020-01-01</th>\n",
       "      <th>2020-02-01</th>\n",
       "      <th>2020-03-01</th>\n",
       "      <th>2020-04-01</th>\n",
       "      <th>2020-05-01</th>\n",
       "      <th>2020-06-01</th>\n",
       "      <th>2020-07-01</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>40.390</td>\n",
       "      <td>39.850</td>\n",
       "      <td>38.000</td>\n",
       "      <td>35.320</td>\n",
       "      <td>33.980</td>\n",
       "      <td>31.950</td>\n",
       "      <td>32.150</td>\n",
       "      <td>29.850</td>\n",
       "      <td>33.930</td>\n",
       "      <td>32.170</td>\n",
       "      <td>...</td>\n",
       "      <td>38.780000</td>\n",
       "      <td>37.580000</td>\n",
       "      <td>38.440000</td>\n",
       "      <td>38.570000</td>\n",
       "      <td>35.870000</td>\n",
       "      <td>33.250000</td>\n",
       "      <td>33.330000</td>\n",
       "      <td>32.500000</td>\n",
       "      <td>35.280000</td>\n",
       "      <td>41.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_prod</th>\n",
       "      <td>24.000</td>\n",
       "      <td>53.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>40.000</td>\n",
       "      <td>56.000</td>\n",
       "      <td>75.000</td>\n",
       "      <td>74.000</td>\n",
       "      <td>82.000</td>\n",
       "      <td>59.000</td>\n",
       "      <td>64.000</td>\n",
       "      <td>...</td>\n",
       "      <td>157.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>161.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>140.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co_domestic</th>\n",
       "      <td>91.000</td>\n",
       "      <td>152.000</td>\n",
       "      <td>108.000</td>\n",
       "      <td>58.000</td>\n",
       "      <td>228.000</td>\n",
       "      <td>213.000</td>\n",
       "      <td>159.000</td>\n",
       "      <td>139.000</td>\n",
       "      <td>137.000</td>\n",
       "      <td>127.000</td>\n",
       "      <td>...</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>437.000000</td>\n",
       "      <td>482.000000</td>\n",
       "      <td>493.000000</td>\n",
       "      <td>401.000000</td>\n",
       "      <td>548.000000</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>472.000000</td>\n",
       "      <td>525.000000</td>\n",
       "      <td>507.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_canola_crush</th>\n",
       "      <td>325.247</td>\n",
       "      <td>307.567</td>\n",
       "      <td>288.000</td>\n",
       "      <td>234.607</td>\n",
       "      <td>306.664</td>\n",
       "      <td>259.121</td>\n",
       "      <td>223.777</td>\n",
       "      <td>288.740</td>\n",
       "      <td>274.977</td>\n",
       "      <td>283.584</td>\n",
       "      <td>...</td>\n",
       "      <td>882.301000</td>\n",
       "      <td>829.303000</td>\n",
       "      <td>899.331000</td>\n",
       "      <td>854.686000</td>\n",
       "      <td>812.633000</td>\n",
       "      <td>881.384000</td>\n",
       "      <td>845.459000</td>\n",
       "      <td>855.008000</td>\n",
       "      <td>864.559000</td>\n",
       "      <td>815.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ca_co_exports</th>\n",
       "      <td>97.685</td>\n",
       "      <td>110.618</td>\n",
       "      <td>105.372</td>\n",
       "      <td>68.013</td>\n",
       "      <td>93.408</td>\n",
       "      <td>147.687</td>\n",
       "      <td>75.383</td>\n",
       "      <td>106.488</td>\n",
       "      <td>93.807</td>\n",
       "      <td>128.998</td>\n",
       "      <td>...</td>\n",
       "      <td>310.118426</td>\n",
       "      <td>251.207234</td>\n",
       "      <td>288.721506</td>\n",
       "      <td>311.512257</td>\n",
       "      <td>248.039262</td>\n",
       "      <td>338.876088</td>\n",
       "      <td>262.566916</td>\n",
       "      <td>340.571679</td>\n",
       "      <td>276.802196</td>\n",
       "      <td>327.788356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cent_ill_sbo</th>\n",
       "      <td>34.660</td>\n",
       "      <td>34.190</td>\n",
       "      <td>32.680</td>\n",
       "      <td>30.080</td>\n",
       "      <td>28.050</td>\n",
       "      <td>25.980</td>\n",
       "      <td>25.870</td>\n",
       "      <td>23.230</td>\n",
       "      <td>22.950</td>\n",
       "      <td>21.790</td>\n",
       "      <td>...</td>\n",
       "      <td>30.140000</td>\n",
       "      <td>30.621000</td>\n",
       "      <td>32.270000</td>\n",
       "      <td>33.040000</td>\n",
       "      <td>30.260000</td>\n",
       "      <td>27.040000</td>\n",
       "      <td>25.690000</td>\n",
       "      <td>25.270000</td>\n",
       "      <td>26.610000</td>\n",
       "      <td>28.710000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  197 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
       "co                   40.390      39.850      38.000      35.320      33.980   \n",
       "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
       "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
       "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
       "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
       "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
       "\n",
       "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
       "co                   31.950      32.150      29.850      33.930      32.170   \n",
       "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
       "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
       "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
       "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
       "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
       "\n",
       "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
       "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
       "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
       "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
       "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
       "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
       "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
       "\n",
       "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
       "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
       "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
       "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
       "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
       "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
       "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
       "\n",
       "date             2020-07-01  \n",
       "co                41.950000  \n",
       "co_prod          140.000000  \n",
       "co_domestic      507.000000  \n",
       "ca_canola_crush  815.000000  \n",
       "ca_co_exports    327.788356  \n",
       "cent_ill_sbo      28.710000  \n",
       "\n",
       "[6 rows x 197 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "n_filters = 32\n",
    "filter_width = 2\n",
    "dilation_rates = [2**i for i in range(7)] * 2 \n",
    "\n",
    "# define an input history series and pass it through a stack of dilated causal convolution blocks\n",
    "history_seq = Input(shape=(None, 1))\n",
    "x = history_seq\n",
    "\n",
    "skips = []\n",
    "for dilation_rate in dilation_rates:\n",
    "    \n",
    "    # preprocessing - equivalent to time-distributed dense\n",
    "    x = Conv1D(16, 1, padding='same', activation='relu')(x) \n",
    "    \n",
    "    # filter\n",
    "    x_f = Conv1D(filters=n_filters,\n",
    "                 kernel_size=filter_width, \n",
    "                 padding='causal',\n",
    "                 dilation_rate=dilation_rate)(x)\n",
    "    \n",
    "    # gate\n",
    "    x_g = Conv1D(filters=n_filters,\n",
    "                 kernel_size=filter_width, \n",
    "                 padding='causal',\n",
    "                 dilation_rate=dilation_rate)(x)\n",
    "    \n",
    "    # combine filter and gating branches\n",
    "    z = Multiply()([Activation('tanh')(x_f),\n",
    "                    Activation('sigmoid')(x_g)])\n",
    "    \n",
    "    # postprocessing - equivalent to time-distributed dense\n",
    "    z = Conv1D(16, 1, padding='same', activation='relu')(z)\n",
    "    \n",
    "    # residual connection\n",
    "    x = Add()([x, z])    \n",
    "    \n",
    "    # collect skip connections\n",
    "    skips.append(z)\n",
    "\n",
    "# add all skip connection outputs \n",
    "out = Activation('relu')(Add()(skips))\n",
    "\n",
    "# final time-distributed dense layers \n",
    "out = Conv1D(128, 1, padding='same')(out)\n",
    "out = Activation('relu')(out)\n",
    "out = Dropout(.2)(out)\n",
    "out = Conv1D(1, 1, padding='same')(out)\n",
    "\n",
    "# extract training target at end\n",
    "def slice(x, seq_length):\n",
    "    return x[:,-seq_length:,:]\n",
    "\n",
    "pred_seq_train = Lambda(slice, arguments={'seq_length':30})(out)\n",
    "\n",
    "model = Model(history_seq, pred_seq_train)\n",
    "model.compile(Adam(), loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 1)]    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, None, 16)     32          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, None, 32)     1056        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, None, 32)     1056        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, None, 32)     0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, None, 32)     0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply (Multiply)             (None, None, 32)     0           activation[0][0]                 \n",
      "                                                                 activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, None, 16)     528         multiply[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, None, 16)     0           conv1d[0][0]                     \n",
      "                                                                 conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, None, 16)     272         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, None, 32)     1056        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, None, 32)     1056        conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, None, 32)     0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, None, 32)     0           conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "multiply_1 (Multiply)           (None, None, 32)     0           activation_2[0][0]               \n",
      "                                                                 activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, None, 16)     528         multiply_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, None, 16)     0           conv1d_4[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, None, 16)     272         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, None, 32)     1056        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, None, 32)     1056        conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, None, 32)     0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, None, 32)     0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_2 (Multiply)           (None, None, 32)     0           activation_4[0][0]               \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, None, 16)     528         multiply_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, None, 16)     0           conv1d_8[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, None, 16)     272         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, None, 32)     1056        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, None, 32)     1056        conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, None, 32)     0           conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, None, 32)     0           conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_3 (Multiply)           (None, None, 32)     0           activation_6[0][0]               \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_15 (Conv1D)              (None, None, 16)     528         multiply_3[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, None, 16)     0           conv1d_12[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_16 (Conv1D)              (None, None, 16)     272         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_17 (Conv1D)              (None, None, 32)     1056        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_18 (Conv1D)              (None, None, 32)     1056        conv1d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, None, 32)     0           conv1d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, None, 32)     0           conv1d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_4 (Multiply)           (None, None, 32)     0           activation_8[0][0]               \n",
      "                                                                 activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_19 (Conv1D)              (None, None, 16)     528         multiply_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, None, 16)     0           conv1d_16[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_20 (Conv1D)              (None, None, 16)     272         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_21 (Conv1D)              (None, None, 32)     1056        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_22 (Conv1D)              (None, None, 32)     1056        conv1d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, None, 32)     0           conv1d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, None, 32)     0           conv1d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_5 (Multiply)           (None, None, 32)     0           activation_10[0][0]              \n",
      "                                                                 activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_23 (Conv1D)              (None, None, 16)     528         multiply_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, None, 16)     0           conv1d_20[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, None, 16)     272         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, None, 32)     1056        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_26 (Conv1D)              (None, None, 32)     1056        conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, None, 32)     0           conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, None, 32)     0           conv1d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, None, 32)     0           activation_12[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_27 (Conv1D)              (None, None, 16)     528         multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, None, 16)     0           conv1d_24[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_28 (Conv1D)              (None, None, 16)     272         add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_29 (Conv1D)              (None, None, 32)     1056        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_30 (Conv1D)              (None, None, 32)     1056        conv1d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, None, 32)     0           conv1d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, None, 32)     0           conv1d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_7 (Multiply)           (None, None, 32)     0           activation_14[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_31 (Conv1D)              (None, None, 16)     528         multiply_7[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, None, 16)     0           conv1d_28[0][0]                  \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_32 (Conv1D)              (None, None, 16)     272         add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_33 (Conv1D)              (None, None, 32)     1056        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_34 (Conv1D)              (None, None, 32)     1056        conv1d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, None, 32)     0           conv1d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, None, 32)     0           conv1d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_8 (Multiply)           (None, None, 32)     0           activation_16[0][0]              \n",
      "                                                                 activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_35 (Conv1D)              (None, None, 16)     528         multiply_8[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, None, 16)     0           conv1d_32[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_36 (Conv1D)              (None, None, 16)     272         add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_37 (Conv1D)              (None, None, 32)     1056        conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_38 (Conv1D)              (None, None, 32)     1056        conv1d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, None, 32)     0           conv1d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, None, 32)     0           conv1d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_9 (Multiply)           (None, None, 32)     0           activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_39 (Conv1D)              (None, None, 16)     528         multiply_9[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, None, 16)     0           conv1d_36[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_40 (Conv1D)              (None, None, 16)     272         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_41 (Conv1D)              (None, None, 32)     1056        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_42 (Conv1D)              (None, None, 32)     1056        conv1d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, None, 32)     0           conv1d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, None, 32)     0           conv1d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_10 (Multiply)          (None, None, 32)     0           activation_20[0][0]              \n",
      "                                                                 activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_43 (Conv1D)              (None, None, 16)     528         multiply_10[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, None, 16)     0           conv1d_40[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_44 (Conv1D)              (None, None, 16)     272         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_45 (Conv1D)              (None, None, 32)     1056        conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_46 (Conv1D)              (None, None, 32)     1056        conv1d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, None, 32)     0           conv1d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, None, 32)     0           conv1d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_11 (Multiply)          (None, None, 32)     0           activation_22[0][0]              \n",
      "                                                                 activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_47 (Conv1D)              (None, None, 16)     528         multiply_11[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, None, 16)     0           conv1d_44[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_48 (Conv1D)              (None, None, 16)     272         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_49 (Conv1D)              (None, None, 32)     1056        conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_50 (Conv1D)              (None, None, 32)     1056        conv1d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, None, 32)     0           conv1d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, None, 32)     0           conv1d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_12 (Multiply)          (None, None, 32)     0           activation_24[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_51 (Conv1D)              (None, None, 16)     528         multiply_12[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, None, 16)     0           conv1d_48[0][0]                  \n",
      "                                                                 conv1d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_52 (Conv1D)              (None, None, 16)     272         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_53 (Conv1D)              (None, None, 32)     1056        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_54 (Conv1D)              (None, None, 32)     1056        conv1d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, None, 32)     0           conv1d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, None, 32)     0           conv1d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "multiply_13 (Multiply)          (None, None, 32)     0           activation_26[0][0]              \n",
      "                                                                 activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_55 (Conv1D)              (None, None, 16)     528         multiply_13[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, None, 16)     0           conv1d_3[0][0]                   \n",
      "                                                                 conv1d_7[0][0]                   \n",
      "                                                                 conv1d_11[0][0]                  \n",
      "                                                                 conv1d_15[0][0]                  \n",
      "                                                                 conv1d_19[0][0]                  \n",
      "                                                                 conv1d_23[0][0]                  \n",
      "                                                                 conv1d_27[0][0]                  \n",
      "                                                                 conv1d_31[0][0]                  \n",
      "                                                                 conv1d_35[0][0]                  \n",
      "                                                                 conv1d_39[0][0]                  \n",
      "                                                                 conv1d_43[0][0]                  \n",
      "                                                                 conv1d_47[0][0]                  \n",
      "                                                                 conv1d_51[0][0]                  \n",
      "                                                                 conv1d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, None, 16)     0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_56 (Conv1D)              (None, None, 128)    2176        activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, None, 128)    0           conv1d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, None, 128)    0           activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_57 (Conv1D)              (None, None, 1)      129         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda (Lambda)                 (None, None, 1)      0           conv1d_57[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 42,833\n",
      "Trainable params: 42,833\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_n_samples = 8\n",
    "batch_size = 2**10\n",
    "epochs = 100\n",
    "\n",
    "# sample of series from train_enc_start to train_enc_end  \n",
    "encoder_input_data = get_time_block_series(series_array, date_to_index, \n",
    "                                           train_enc_start, train_enc_end)[:first_n_samples]\n",
    "\n",
    "encoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\n",
    "\n",
    "# sample of series from train_pred_start to train_pred_end \n",
    "decoder_target_data = get_time_block_series(series_array, date_to_index, \n",
    "                                            train_pred_start, train_pred_end)[:first_n_samples]\n",
    "\n",
    "decoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)\n",
    "\n",
    "# we append a lagged history of the target series to the input data, \n",
    "# so that we can train with teacher forcing\n",
    "lagged_target_history = decoder_target_data[:,:-1,:1]\n",
    "encoder_input_data = np.concatenate([encoder_input_data, lagged_target_history], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 561ms/step - loss: 0.5316 - val_loss: 0.3430\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4837 - val_loss: 0.3229\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4389 - val_loss: 0.3060\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.4124 - val_loss: 0.2888\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.3716 - val_loss: 0.2710\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.3304 - val_loss: 0.2533\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2676 - val_loss: 0.2421\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2286 - val_loss: 0.2572\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2233 - val_loss: 0.2890\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2393 - val_loss: 0.2875\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.2451 - val_loss: 0.2640\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.2198 - val_loss: 0.2367\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.1990 - val_loss: 0.2186\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1998 - val_loss: 0.2071\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1932 - val_loss: 0.1990\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1920 - val_loss: 0.1926\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.2047 - val_loss: 0.1853\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1851 - val_loss: 0.1774\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1725 - val_loss: 0.1706\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1614 - val_loss: 0.1652\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1626 - val_loss: 0.1591\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.1553 - val_loss: 0.1544\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1507 - val_loss: 0.1492\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1522 - val_loss: 0.1395\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1549 - val_loss: 0.1267\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1450 - val_loss: 0.1132\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1407 - val_loss: 0.1030\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1272 - val_loss: 0.0950\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1250 - val_loss: 0.0902\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1283 - val_loss: 0.0873\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1249 - val_loss: 0.0865\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1315 - val_loss: 0.0862\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1123 - val_loss: 0.0875\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1109 - val_loss: 0.0903\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1158 - val_loss: 0.0921\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1191 - val_loss: 0.0920\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1210 - val_loss: 0.0901\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1121 - val_loss: 0.0891\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1084 - val_loss: 0.0886\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1082 - val_loss: 0.0876\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1097 - val_loss: 0.0862\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1074 - val_loss: 0.0847\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1124 - val_loss: 0.0825\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1075 - val_loss: 0.0806\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1144 - val_loss: 0.0794\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1000 - val_loss: 0.0786\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1077 - val_loss: 0.0779\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1111 - val_loss: 0.0780\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1096 - val_loss: 0.0783\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0991 - val_loss: 0.0798\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1004 - val_loss: 0.0807\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1067 - val_loss: 0.0818\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1017 - val_loss: 0.0832\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1034 - val_loss: 0.0832\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.1071 - val_loss: 0.0817\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0928 - val_loss: 0.0792\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0995 - val_loss: 0.0777\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0998 - val_loss: 0.0769\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0905 - val_loss: 0.0765\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0939 - val_loss: 0.0767\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1043 - val_loss: 0.0775\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0990 - val_loss: 0.0771\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1039 - val_loss: 0.0776\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0937 - val_loss: 0.0800\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0985 - val_loss: 0.0809\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0964 - val_loss: 0.0809\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.1009 - val_loss: 0.0801\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0952 - val_loss: 0.0785\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0924 - val_loss: 0.0768\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0983 - val_loss: 0.0759\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0925 - val_loss: 0.0759\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0896 - val_loss: 0.0766\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0962 - val_loss: 0.0764\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0949 - val_loss: 0.0758\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0975 - val_loss: 0.0753\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0951 - val_loss: 0.0757\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0974 - val_loss: 0.0771\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0886 - val_loss: 0.0778\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.1001 - val_loss: 0.0774\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0946 - val_loss: 0.0766\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0979 - val_loss: 0.0757\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0886 - val_loss: 0.0751\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0875 - val_loss: 0.0753\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0951 - val_loss: 0.0754\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0963 - val_loss: 0.0748\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0930 - val_loss: 0.0751\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0957 - val_loss: 0.0751\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0981 - val_loss: 0.0749\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0799 - val_loss: 0.0749\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0951 - val_loss: 0.0748\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0919 - val_loss: 0.0755\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0966 - val_loss: 0.0755\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0921 - val_loss: 0.0751\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0965 - val_loss: 0.0762\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0876 - val_loss: 0.0769\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.0946 - val_loss: 0.0773\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0907 - val_loss: 0.0765\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0925 - val_loss: 0.0758\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0875 - val_loss: 0.0750\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.0929 - val_loss: 0.0755\n"
     ]
    }
   ],
   "source": [
    "model.compile(Adam(), loss='mean_absolute_error')\n",
    "\n",
    "history = model.fit(encoder_input_data, decoder_target_data,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(np.exp(history.history['loss']))\n",
    "plt.plot(np.exp(history.history['val_loss']))\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.legend(['Train','Validation']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(input_sequence):\n",
    "\n",
    "    history_sequence = input_sequence.copy()\n",
    "    pred_sequence = np.zeros((1,30,1)) # initialize output (pred_steps time steps)  \n",
    "    \n",
    "    for i in range(pred_steps):\n",
    "        \n",
    "        # record next time step prediction (last time step of model output) \n",
    "        last_step_pred = model.predict(history_sequence)[0,-1,0]\n",
    "        pred_sequence[0,i,0] = last_step_pred\n",
    "        \n",
    "        # add the next time step prediction to the history sequence\n",
    "        history_sequence = np.concatenate([history_sequence, \n",
    "                                           last_step_pred.reshape(-1,1,1)], axis=1)\n",
    "\n",
    "    return pred_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\n",
    "encoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\n",
    "decoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\n",
    "decoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\n",
    "\n",
    "    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \n",
    "    pred_series = predict_sequence(encode_series)\n",
    "    \n",
    "    encode_series = encode_series.reshape(-1,1)\n",
    "    pred_series = pred_series.reshape(-1,1)  \n",
    "    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\n",
    "    \n",
    "    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\n",
    "    x_encode = encode_series_tail.shape[0]\n",
    "    \n",
    "    #plt.figure(figsize=(10,6))   \n",
    "\n",
    "    plt.plot(range(1,x_encode+1),encode_series_tail)\n",
    "    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\n",
    "    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\n",
    "    \n",
    "    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\n",
    "    plt.legend(['Encoding Series','Target Series','Predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 30 is out of bounds for axis 1 with size 30",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-d943ba3f8584>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# sp500 prediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m predict_and_plot(encoder_input_data, decoder_target_data, \n\u001b[1;32m----> 3\u001b[1;33m                  sample_ind=0, enc_tail_len=10)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-3120674c5a8f>\u001b[0m in \u001b[0;36mpredict_and_plot\u001b[1;34m(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mencode_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder_input_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msample_ind\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msample_ind\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mpred_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencode_series\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mencode_series\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencode_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-4e507221b00f>\u001b[0m in \u001b[0;36mpredict_sequence\u001b[1;34m(input_sequence)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# record next time step prediction (last time step of model output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mlast_step_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mpred_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_step_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;31m# add the next time step prediction to the history sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 30 is out of bounds for axis 1 with size 30"
     ]
    }
   ],
   "source": [
    "# sp500 prediction\n",
    "predict_and_plot(encoder_input_data, decoder_target_data, \n",
    "                 sample_ind=0, enc_tail_len=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[1;32m<ipython-input-23-4e507221b00f>\u001b[0m(10)\u001b[0;36mpredict_sequence\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m      8 \u001b[1;33m        \u001b[1;31m# record next time step prediction (last time step of model output)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m      9 \u001b[1;33m        \u001b[0mlast_step_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory_sequence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m---> 10 \u001b[1;33m        \u001b[0mpred_sequence\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlast_step_pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     11 \u001b[1;33m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[1;32m     12 \u001b[1;33m        \u001b[1;31m# add the next time step prediction to the history sequence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  last_step_pred\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.03533025\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  %who\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  dir()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['history_sequence', 'i', 'input_sequence', 'last_step_pred', 'pred_sequence']\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  input_sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[[-0.23219008],\n",
      "        [-0.16010535],\n",
      "        [-0.17512065],\n",
      "        [-0.20897004],\n",
      "        [-0.17966956],\n",
      "        [-0.18119047],\n",
      "        [-0.1673346 ],\n",
      "        [-0.10925925],\n",
      "        [-0.0708197 ],\n",
      "        [-0.00552896],\n",
      "        [-0.0074461 ],\n",
      "        [ 0.08650631],\n",
      "        [ 0.15712829],\n",
      "        [ 0.2171463 ],\n",
      "        [ 0.23587628],\n",
      "        [ 0.3216889 ],\n",
      "        [ 0.41591059],\n",
      "        [ 0.44304537],\n",
      "        [ 0.42770891],\n",
      "        [ 0.4498168 ],\n",
      "        [ 0.48587107],\n",
      "        [ 0.45560377],\n",
      "        [ 0.28798836],\n",
      "        [ 0.17380879],\n",
      "        [-0.00128177],\n",
      "        [-0.11660439],\n",
      "        [-0.18934131],\n",
      "        [-0.16010535],\n",
      "        [-0.24319542],\n",
      "        [-0.27055691],\n",
      "        [-0.16010535],\n",
      "        [-0.07880241],\n",
      "        [-0.06923077],\n",
      "        [-0.12041664],\n",
      "        [-0.0381911 ],\n",
      "        [-0.12184999],\n",
      "        [-0.08040662],\n",
      "        [-0.01343414],\n",
      "        [-0.00467808],\n",
      "        [-0.06991143],\n",
      "        [-0.07263871],\n",
      "        [-0.05549027],\n",
      "        [-0.06290021],\n",
      "        [-0.1059597 ],\n",
      "        [-0.09635887],\n",
      "        [-0.02205117],\n",
      "        [ 0.03083108],\n",
      "        [ 0.0353356 ],\n",
      "        [ 0.10363364],\n",
      "        [ 0.15983758],\n",
      "        [ 0.22376715],\n",
      "        [ 0.25130331],\n",
      "        [ 0.25590177],\n",
      "        [ 0.25639321],\n",
      "        [ 0.29036573],\n",
      "        [ 0.27553411],\n",
      "        [ 0.26568499],\n",
      "        [ 0.27585539],\n",
      "        [ 0.26503575],\n",
      "        [ 0.25655697],\n",
      "        [ 0.22224315],\n",
      "        [ 0.22781984],\n",
      "        [ 0.20859339],\n",
      "        [ 0.20721811],\n",
      "        [ 0.22680821],\n",
      "        [ 0.25639321],\n",
      "        [ 0.28687699],\n",
      "        [ 0.24535975],\n",
      "        [ 0.24502852],\n",
      "        [ 0.30825137],\n",
      "        [ 0.29919164],\n",
      "        [ 0.30700662],\n",
      "        [ 0.27279901],\n",
      "        [ 0.2291671 ],\n",
      "        [ 0.21765715],\n",
      "        [ 0.23921407],\n",
      "        [ 0.25459008],\n",
      "        [ 0.24552533],\n",
      "        [ 0.31213125],\n",
      "        [ 0.30794032],\n",
      "        [ 0.26389855],\n",
      "        [ 0.19458053],\n",
      "        [ 0.10363364],\n",
      "        [ 0.07988506],\n",
      "        [ 0.02362273],\n",
      "        [ 0.00526594],\n",
      "        [-0.03665315],\n",
      "        [-0.08823535],\n",
      "        [-0.01321966],\n",
      "        [ 0.05815795],\n",
      "        [ 0.08767023],\n",
      "        [ 0.05355472],\n",
      "        [ 0.03349529],\n",
      "        [-0.02248398],\n",
      "        [-0.08754211],\n",
      "        [-0.11256973],\n",
      "        [-0.07971879],\n",
      "        [-0.10666583],\n",
      "        [-0.13435917],\n",
      "        [-0.12065539],\n",
      "        [-0.1487444 ],\n",
      "        [-0.18017627],\n",
      "        [-0.26447282],\n",
      "        [-0.26778683],\n",
      "        [-0.22739646],\n",
      "        [-0.26226957],\n",
      "        [-0.34990638],\n",
      "        [-0.40484151],\n",
      "        [-0.37299367],\n",
      "        [-0.43348385],\n",
      "        [-0.3529139 ],\n",
      "        [-0.36077605],\n",
      "        [-0.30355017],\n",
      "        [-0.28649462],\n",
      "        [-0.24589813],\n",
      "        [-0.29243103],\n",
      "        [-0.27027956],\n",
      "        [-0.31045469],\n",
      "        [-0.21524949],\n",
      "        [-0.1906209 ],\n",
      "        [-0.15169571],\n",
      "        [-0.14067294],\n",
      "        [-0.13484343],\n",
      "        [-0.17009046],\n",
      "        [-0.20610508],\n",
      "        [-0.22659975],\n",
      "        [-0.2502377 ],\n",
      "        [-0.22474323],\n",
      "        [-0.23861752],\n",
      "        [-0.18959709],\n",
      "        [-0.1625923 ],\n",
      "        [-0.1524349 ],\n",
      "        [-0.16933811],\n",
      "        [-0.15021897],\n",
      "        [-0.18093683],\n",
      "        [-0.18500291]]])\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  global()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** SyntaxError: invalid syntax\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  globals()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__name__': '__main__', '__doc__': 'Automatically created module for IPython interactive environment', '__package__': None, '__loader__': None, '__spec__': None, '__builtin__': <module 'builtins' (built-in)>, '__builtins__': <module 'builtins' (built-in)>, '_ih': ['', \"import pandas as pd\\nimport numpy as np\\nimport missingno as mn\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom datetime import timedelta\\nfrom keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam\\nget_ipython().run_line_magic('matplotlib', 'inline')\", \"# load data\\nraw = pd.read_csv('../arima_fc/data/canola_oil_v2.csv')\\nraw.index = pd.to_datetime(raw.date).dt.date\", 'raw.head()', 'mn.matrix(raw)', 'mn.matrix(raw[raw.co.notnull()])\\ndf = raw[raw.co.notnull()]', \"df = df.drop('date',axis=1)\\ndf.head()\", 'df = df.T\\ndf.head()', 'data_start_date = df.columns[1]\\ndata_end_date = df.columns[-1]\\n\\npred_steps = 900\\npred_length=timedelta(pred_steps)\\nprint(pred_length)\\nfirst_day = pd.to_datetime(data_start_date)\\nlast_day = pd.to_datetime(data_end_date)\\n\\nval_pred_start = last_day - pred_length + timedelta(1)\\nval_pred_end = last_day\\n\\ntrain_pred_start = val_pred_start - pred_length\\ntrain_pred_end = val_pred_start - timedelta(days=1)\\n\\nenc_length = train_pred_start - first_day\\n\\ntrain_enc_start = first_day\\ntrain_enc_end = train_enc_start + enc_length - timedelta(1)\\n\\nval_enc_start = train_enc_start + pred_length\\nval_enc_end = val_enc_start + enc_length - timedelta(1) ', \"print('Train encoding:', train_enc_start, '-', train_enc_end)\\nprint('Train prediction:', train_pred_start, '-', train_pred_end, '\\\\n')\\nprint('Val encoding:', val_enc_start, '-', val_enc_end)\\nprint('Val prediction:', val_pred_start, '-', val_pred_end)\\n\\nprint('\\\\nEncoding interval:', enc_length.days)\\nprint('Prediction interval:', pred_length.days)\", 'date_to_index = pd.Series(index=pd.Index([pd.to_datetime(c) for c in df.columns[1:]]),\\n                          data=[i for i in range(len(df.columns[1:]))])\\n\\nseries_array = df[df.columns[1:]].values\\n\\ndef get_time_block_series(series_array, date_to_index, start_date, end_date):\\n    \\n    inds = date_to_index[start_date:end_date]\\n    return series_array[:,inds]\\n\\ndef transform_series_encode(series_array):\\n    \\n    series_array = np.log(series_array)\\n    series_mean = series_array.mean(axis=1).reshape(-1,1) \\n    series_array = series_array - series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array, series_mean\\n\\ndef transform_series_decode(series_array, encode_series_mean):\\n    \\n    series_array = np.log(series_array)\\n    series_array = series_array - encode_series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array', 'df', 'from keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam', \"# hyper-parameters\\nn_filters = 32\\nfilter_width = 2\\ndilation_rates = [2**i for i in range(7)] * 2 \\n\\n# define an input history series and pass it through a stack of dilated causal convolution blocks\\nhistory_seq = Input(shape=(None, 1))\\nx = history_seq\\n\\nskips = []\\nfor dilation_rate in dilation_rates:\\n    \\n    # preprocessing - equivalent to time-distributed dense\\n    x = Conv1D(16, 1, padding='same', activation='relu')(x) \\n    \\n    # filter\\n    x_f = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # gate\\n    x_g = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # combine filter and gating branches\\n    z = Multiply()([Activation('tanh')(x_f),\\n                    Activation('sigmoid')(x_g)])\\n    \\n    # postprocessing - equivalent to time-distributed dense\\n    z = Conv1D(16, 1, padding='same', activation='relu')(z)\\n    \\n    # residual connection\\n    x = Add()([x, z])    \\n    \\n    # collect skip connections\\n    skips.append(z)\\n\\n# add all skip connection outputs \\nout = Activation('relu')(Add()(skips))\\n\\n# final time-distributed dense layers \\nout = Conv1D(128, 1, padding='same')(out)\\nout = Activation('relu')(out)\\nout = Dropout(.2)(out)\\nout = Conv1D(1, 1, padding='same')(out)\\n\\n# extract training target at end\\ndef slice(x, seq_length):\\n    return x[:,-seq_length:,:]\\n\\npred_seq_train = Lambda(slice, arguments={'seq_length':30})(out)\\n\\nmodel = Model(history_seq, pred_seq_train)\\nmodel.compile(Adam(), loss='mean_absolute_error')\", 'model.summary()', 'first_n_samples = 8\\nbatch_size = 2**10\\nepochs = 100\\n\\n# sample of series from train_enc_start to train_enc_end  \\nencoder_input_data = get_time_block_series(series_array, date_to_index, \\n                                           train_enc_start, train_enc_end)[:first_n_samples]\\n\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\n\\n# sample of series from train_pred_start to train_pred_end \\ndecoder_target_data = get_time_block_series(series_array, date_to_index, \\n                                            train_pred_start, train_pred_end)[:first_n_samples]\\n\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)\\n\\n# we append a lagged history of the target series to the input data, \\n# so that we can train with teacher forcing\\nlagged_target_history = decoder_target_data[:,:-1,:1]\\nencoder_input_data = np.concatenate([encoder_input_data, lagged_target_history], axis=1)', \"model.compile(Adam(), loss='mean_absolute_error')\\n\\nhistory = model.fit(encoder_input_data, decoder_target_data,\\n                    batch_size=batch_size,\\n                    epochs=epochs,\\n                    validation_split=0.20)\", \"plt.plot(np.exp(history.history['loss']))\\nplt.plot(np.exp(history.history['val_loss']))\\n\\nplt.xlabel('Epoch')\\nplt.ylabel('Mean Absolute Error Loss')\\nplt.title('Loss Over Time')\\nplt.legend(['Train','Validation']);\", 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,pred_steps,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\nvf\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,30,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', \"get_ipython().run_line_magic('debug', '')\"], '_oh': {1: '[{\"varName\": \"ipywidgets\", \"varType\": \"NoneType\", \"varSize\": \"16\", \"varShape\": \"\", \"varContent\": \"None\", \"isMatrix\": false, \"isWidget\": null}]', 3:                   date  co  co_prod  co_domestic  ca_canola_crush  \\\n",
      "date                                                                \n",
      "2000-01-01  2000-01-01 NaN      NaN          NaN          273.365   \n",
      "2000-02-01  2000-02-01 NaN      NaN          NaN          231.914   \n",
      "2000-03-01  2000-03-01 NaN      NaN          NaN          301.705   \n",
      "2000-04-01  2000-04-01 NaN      NaN          NaN          205.655   \n",
      "2000-05-01  2000-05-01 NaN      NaN          NaN          265.540   \n",
      "\n",
      "            ca_co_exports  cent_ill_sbo  \n",
      "date                                     \n",
      "2000-01-01         78.335         15.56  \n",
      "2000-02-01         98.451         15.09  \n",
      "2000-03-01         87.800         16.22  \n",
      "2000-04-01         81.074         17.52  \n",
      "2000-05-01         61.784         16.75  , 4: <matplotlib.axes._subplots.AxesSubplot object at 0x0000016336F41988>, 5: '[{\"varName\": \"raw\", \"varType\": \"DataFrame\", \"varSize\": \"17472\", \"varShape\": \"273 rows x 7 cols\", \"varContent\": \"Columns: date, co, co_prod, co_domestic, ca_canola_crush, ca_co_exports, cent_ill_sbo\", \"isMatrix\": true, \"isWidget\": false}]', 6:                co  co_prod  co_domestic  ca_canola_crush  ca_co_exports  \\\n",
      "date                                                                      \n",
      "2004-03-01  40.39     24.0         91.0          325.247         97.685   \n",
      "2004-04-01  39.85     53.0        152.0          307.567        110.618   \n",
      "2004-05-01  38.00     56.0        108.0          288.000        105.372   \n",
      "2004-06-01  35.32     40.0         58.0          234.607         68.013   \n",
      "2004-07-01  33.98     56.0        228.0          306.664         93.408   \n",
      "\n",
      "            cent_ill_sbo  \n",
      "date                      \n",
      "2004-03-01         34.66  \n",
      "2004-04-01         34.19  \n",
      "2004-05-01         32.68  \n",
      "2004-06-01         30.08  \n",
      "2004-07-01         28.05  , 7: date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "\n",
      "[5 rows x 197 columns], 11: date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "cent_ill_sbo      28.710000  \n",
      "\n",
      "[6 rows x 197 columns]}, '_dh': ['C:\\\\Users\\\\Hamed\\\\Documents\\\\GitHub\\\\wavenet'], 'In': ['', \"import pandas as pd\\nimport numpy as np\\nimport missingno as mn\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom datetime import timedelta\\nfrom keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam\\nget_ipython().run_line_magic('matplotlib', 'inline')\", \"# load data\\nraw = pd.read_csv('../arima_fc/data/canola_oil_v2.csv')\\nraw.index = pd.to_datetime(raw.date).dt.date\", 'raw.head()', 'mn.matrix(raw)', 'mn.matrix(raw[raw.co.notnull()])\\ndf = raw[raw.co.notnull()]', \"df = df.drop('date',axis=1)\\ndf.head()\", 'df = df.T\\ndf.head()', 'data_start_date = df.columns[1]\\ndata_end_date = df.columns[-1]\\n\\npred_steps = 900\\npred_length=timedelta(pred_steps)\\nprint(pred_length)\\nfirst_day = pd.to_datetime(data_start_date)\\nlast_day = pd.to_datetime(data_end_date)\\n\\nval_pred_start = last_day - pred_length + timedelta(1)\\nval_pred_end = last_day\\n\\ntrain_pred_start = val_pred_start - pred_length\\ntrain_pred_end = val_pred_start - timedelta(days=1)\\n\\nenc_length = train_pred_start - first_day\\n\\ntrain_enc_start = first_day\\ntrain_enc_end = train_enc_start + enc_length - timedelta(1)\\n\\nval_enc_start = train_enc_start + pred_length\\nval_enc_end = val_enc_start + enc_length - timedelta(1) ', \"print('Train encoding:', train_enc_start, '-', train_enc_end)\\nprint('Train prediction:', train_pred_start, '-', train_pred_end, '\\\\n')\\nprint('Val encoding:', val_enc_start, '-', val_enc_end)\\nprint('Val prediction:', val_pred_start, '-', val_pred_end)\\n\\nprint('\\\\nEncoding interval:', enc_length.days)\\nprint('Prediction interval:', pred_length.days)\", 'date_to_index = pd.Series(index=pd.Index([pd.to_datetime(c) for c in df.columns[1:]]),\\n                          data=[i for i in range(len(df.columns[1:]))])\\n\\nseries_array = df[df.columns[1:]].values\\n\\ndef get_time_block_series(series_array, date_to_index, start_date, end_date):\\n    \\n    inds = date_to_index[start_date:end_date]\\n    return series_array[:,inds]\\n\\ndef transform_series_encode(series_array):\\n    \\n    series_array = np.log(series_array)\\n    series_mean = series_array.mean(axis=1).reshape(-1,1) \\n    series_array = series_array - series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array, series_mean\\n\\ndef transform_series_decode(series_array, encode_series_mean):\\n    \\n    series_array = np.log(series_array)\\n    series_array = series_array - encode_series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array', 'df', 'from keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam', \"# hyper-parameters\\nn_filters = 32\\nfilter_width = 2\\ndilation_rates = [2**i for i in range(7)] * 2 \\n\\n# define an input history series and pass it through a stack of dilated causal convolution blocks\\nhistory_seq = Input(shape=(None, 1))\\nx = history_seq\\n\\nskips = []\\nfor dilation_rate in dilation_rates:\\n    \\n    # preprocessing - equivalent to time-distributed dense\\n    x = Conv1D(16, 1, padding='same', activation='relu')(x) \\n    \\n    # filter\\n    x_f = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # gate\\n    x_g = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # combine filter and gating branches\\n    z = Multiply()([Activation('tanh')(x_f),\\n                    Activation('sigmoid')(x_g)])\\n    \\n    # postprocessing - equivalent to time-distributed dense\\n    z = Conv1D(16, 1, padding='same', activation='relu')(z)\\n    \\n    # residual connection\\n    x = Add()([x, z])    \\n    \\n    # collect skip connections\\n    skips.append(z)\\n\\n# add all skip connection outputs \\nout = Activation('relu')(Add()(skips))\\n\\n# final time-distributed dense layers \\nout = Conv1D(128, 1, padding='same')(out)\\nout = Activation('relu')(out)\\nout = Dropout(.2)(out)\\nout = Conv1D(1, 1, padding='same')(out)\\n\\n# extract training target at end\\ndef slice(x, seq_length):\\n    return x[:,-seq_length:,:]\\n\\npred_seq_train = Lambda(slice, arguments={'seq_length':30})(out)\\n\\nmodel = Model(history_seq, pred_seq_train)\\nmodel.compile(Adam(), loss='mean_absolute_error')\", 'model.summary()', 'first_n_samples = 8\\nbatch_size = 2**10\\nepochs = 100\\n\\n# sample of series from train_enc_start to train_enc_end  \\nencoder_input_data = get_time_block_series(series_array, date_to_index, \\n                                           train_enc_start, train_enc_end)[:first_n_samples]\\n\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\n\\n# sample of series from train_pred_start to train_pred_end \\ndecoder_target_data = get_time_block_series(series_array, date_to_index, \\n                                            train_pred_start, train_pred_end)[:first_n_samples]\\n\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)\\n\\n# we append a lagged history of the target series to the input data, \\n# so that we can train with teacher forcing\\nlagged_target_history = decoder_target_data[:,:-1,:1]\\nencoder_input_data = np.concatenate([encoder_input_data, lagged_target_history], axis=1)', \"model.compile(Adam(), loss='mean_absolute_error')\\n\\nhistory = model.fit(encoder_input_data, decoder_target_data,\\n                    batch_size=batch_size,\\n                    epochs=epochs,\\n                    validation_split=0.20)\", \"plt.plot(np.exp(history.history['loss']))\\nplt.plot(np.exp(history.history['val_loss']))\\n\\nplt.xlabel('Epoch')\\nplt.ylabel('Mean Absolute Error Loss')\\nplt.title('Loss Over Time')\\nplt.legend(['Train','Validation']);\", 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,pred_steps,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\nvf\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,30,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', \"get_ipython().run_line_magic('debug', '')\"], 'Out': {1: '[{\"varName\": \"ipywidgets\", \"varType\": \"NoneType\", \"varSize\": \"16\", \"varShape\": \"\", \"varContent\": \"None\", \"isMatrix\": false, \"isWidget\": null}]', 3:                   date  co  co_prod  co_domestic  ca_canola_crush  \\\n",
      "date                                                                \n",
      "2000-01-01  2000-01-01 NaN      NaN          NaN          273.365   \n",
      "2000-02-01  2000-02-01 NaN      NaN          NaN          231.914   \n",
      "2000-03-01  2000-03-01 NaN      NaN          NaN          301.705   \n",
      "2000-04-01  2000-04-01 NaN      NaN          NaN          205.655   \n",
      "2000-05-01  2000-05-01 NaN      NaN          NaN          265.540   \n",
      "\n",
      "            ca_co_exports  cent_ill_sbo  \n",
      "date                                     \n",
      "2000-01-01         78.335         15.56  \n",
      "2000-02-01         98.451         15.09  \n",
      "2000-03-01         87.800         16.22  \n",
      "2000-04-01         81.074         17.52  \n",
      "2000-05-01         61.784         16.75  , 4: <matplotlib.axes._subplots.AxesSubplot object at 0x0000016336F41988>, 5: '[{\"varName\": \"raw\", \"varType\": \"DataFrame\", \"varSize\": \"17472\", \"varShape\": \"273 rows x 7 cols\", \"varContent\": \"Columns: date, co, co_prod, co_domestic, ca_canola_crush, ca_co_exports, cent_ill_sbo\", \"isMatrix\": true, \"isWidget\": false}]', 6:                co  co_prod  co_domestic  ca_canola_crush  ca_co_exports  \\\n",
      "date                                                                      \n",
      "2004-03-01  40.39     24.0         91.0          325.247         97.685   \n",
      "2004-04-01  39.85     53.0        152.0          307.567        110.618   \n",
      "2004-05-01  38.00     56.0        108.0          288.000        105.372   \n",
      "2004-06-01  35.32     40.0         58.0          234.607         68.013   \n",
      "2004-07-01  33.98     56.0        228.0          306.664         93.408   \n",
      "\n",
      "            cent_ill_sbo  \n",
      "date                      \n",
      "2004-03-01         34.66  \n",
      "2004-04-01         34.19  \n",
      "2004-05-01         32.68  \n",
      "2004-06-01         30.08  \n",
      "2004-07-01         28.05  , 7: date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "\n",
      "[5 rows x 197 columns], 11: date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "cent_ill_sbo      28.710000  \n",
      "\n",
      "[6 rows x 197 columns]}, 'get_ipython': <function get_ipython at 0x0000016307ECD318>, 'exit': <IPython.core.autocall.ZMQExitAutocall object at 0x000001630BABD3C8>, 'quit': <IPython.core.autocall.ZMQExitAutocall object at 0x000001630BABD3C8>, '_': date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "cent_ill_sbo      28.710000  \n",
      "\n",
      "[6 rows x 197 columns], '__': date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "\n",
      "[5 rows x 197 columns], '___': '[{\"varName\": \"df\", \"varType\": \"DataFrame\", \"varSize\": \"11032\", \"varShape\": \"197 rows x 6 cols\", \"varContent\": \"Columns: co, co_prod, co_domestic, ca_canola_crush, ca_co_exports, cent_ill_sbo\", \"isMatrix\": true, \"isWidget\": false}, {\"varName\": \"raw\", \"varType\": \"DataFrame\", \"varSize\": \"17472\", \"varShape\": \"273 rows x 7 cols\", \"varContent\": \"Columns: date, co, co_prod, co_domestic, ca_canola_crush, ca_co_exports, cent_ill_sbo\", \"isMatrix\": true, \"isWidget\": false}]', 'json': <module 'json' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\json\\\\__init__.py'>, 'sys': <module 'sys' (built-in)>, 'NamespaceMagics': <class 'IPython.core.magics.namespace.NamespaceMagics'>, '_jupyterlab_variableinspector_nms': <IPython.core.magics.namespace.NamespaceMagics object at 0x000001630BB66F08>, '_jupyterlab_variableinspector_Jupyter': <ipykernel.zmqshell.ZMQInteractiveShell object at 0x0000016309D0E888>, 'np': <module 'numpy' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'>, 'pd': <module 'pandas' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>, 'pyspark': None, 'tf': <module 'tensorflow' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\tensorflow\\\\__init__.py'>, 'ipywidgets': <module 'ipywidgets' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\ipywidgets\\\\__init__.py'>, '_check_imported': <function _check_imported at 0x000001630BB02708>, '_jupyterlab_variableinspector_getsizeof': <function _jupyterlab_variableinspector_getsizeof at 0x000001630BB024C8>, '_jupyterlab_variableinspector_getshapeof': <function _jupyterlab_variableinspector_getshapeof at 0x000001630BB021F8>, '_jupyterlab_variableinspector_getcontentof': <function _jupyterlab_variableinspector_getcontentof at 0x000001630BB02C18>, '_jupyterlab_variableinspector_is_matrix': <function _jupyterlab_variableinspector_is_matrix at 0x000001630BB02F78>, '_jupyterlab_variableinspector_is_widget': <function _jupyterlab_variableinspector_is_widget at 0x000001630BB02DC8>, '_jupyterlab_variableinspector_dict_list': <function _jupyterlab_variableinspector_dict_list at 0x000001630BB02CA8>, '_jupyterlab_variableinspector_getmatrixcontent': <function _jupyterlab_variableinspector_getmatrixcontent at 0x000001630BB580D8>, '_jupyterlab_variableinspector_displaywidget': <function _jupyterlab_variableinspector_displaywidget at 0x000001630BB58438>, '_jupyterlab_variableinspector_default': <function _jupyterlab_variableinspector_default at 0x000001630BB58558>, '_jupyterlab_variableinspector_deletevariable': <function _jupyterlab_variableinspector_deletevariable at 0x000001630BB58678>, '_1': '[{\"varName\": \"ipywidgets\", \"varType\": \"NoneType\", \"varSize\": \"16\", \"varShape\": \"\", \"varContent\": \"None\", \"isMatrix\": false, \"isWidget\": null}]', '_i': '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', '_ii': \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '_iii': 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', '_i1': 'import pandas as pd\\nimport numpy as np\\nimport missingno as mn\\nimport seaborn as sns\\nimport matplotlib.pyplot as plt\\nfrom datetime import timedelta\\nfrom keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam\\n%matplotlib inline', 'mn': <module 'missingno' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\missingno\\\\__init__.py'>, 'sns': <module 'seaborn' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\seaborn\\\\__init__.py'>, 'plt': <module 'matplotlib.pyplot' from 'C:\\\\Users\\\\Hamed\\\\anaconda3\\\\lib\\\\site-packages\\\\matplotlib\\\\pyplot.py'>, 'timedelta': <class 'datetime.timedelta'>, 'Model': <class 'tensorflow.python.keras.engine.training.Model'>, 'Input': <function Input at 0x0000016333DE7318>, 'Conv1D': <class 'tensorflow.python.keras.layers.convolutional.Conv1D'>, 'Dense': <class 'tensorflow.python.keras.layers.core.Dense'>, 'Activation': <class 'tensorflow.python.keras.layers.core.Activation'>, 'Dropout': <class 'tensorflow.python.keras.layers.core.Dropout'>, 'Lambda': <class 'tensorflow.python.keras.layers.core.Lambda'>, 'Multiply': <class 'tensorflow.python.keras.layers.merge.Multiply'>, 'Add': <class 'tensorflow.python.keras.layers.merge.Add'>, 'Concatenate': <class 'tensorflow.python.keras.layers.merge.Concatenate'>, 'Adam': <class 'tensorflow.python.keras.optimizer_v2.adam.Adam'>, '_i2': \"# load data\\nraw = pd.read_csv('../arima_fc/data/canola_oil_v2.csv')\\nraw.index = pd.to_datetime(raw.date).dt.date\", 'raw':                   date  co  co_prod  co_domestic  ca_canola_crush  \\\n",
      "date                                                                \n",
      "2000-01-01  2000-01-01 NaN      NaN          NaN          273.365   \n",
      "2000-02-01  2000-02-01 NaN      NaN          NaN          231.914   \n",
      "2000-03-01  2000-03-01 NaN      NaN          NaN          301.705   \n",
      "2000-04-01  2000-04-01 NaN      NaN          NaN          205.655   \n",
      "2000-05-01  2000-05-01 NaN      NaN          NaN          265.540   \n",
      "...                ...  ..      ...          ...              ...   \n",
      "2022-05-01  2022-05-01 NaN    136.0        436.0              NaN   \n",
      "2022-06-01  2022-06-01 NaN    127.0        509.0              NaN   \n",
      "2022-07-01  2022-07-01 NaN    142.0        504.0              NaN   \n",
      "2022-08-01  2022-08-01 NaN    133.0        517.0              NaN   \n",
      "2022-09-01  2022-09-01 NaN    155.0        489.0              NaN   \n",
      "\n",
      "            ca_co_exports  cent_ill_sbo  \n",
      "date                                     \n",
      "2000-01-01         78.335         15.56  \n",
      "2000-02-01         98.451         15.09  \n",
      "2000-03-01         87.800         16.22  \n",
      "2000-04-01         81.074         17.52  \n",
      "2000-05-01         61.784         16.75  \n",
      "...                   ...           ...  \n",
      "2022-05-01            NaN           NaN  \n",
      "2022-06-01            NaN           NaN  \n",
      "2022-07-01            NaN           NaN  \n",
      "2022-08-01            NaN           NaN  \n",
      "2022-09-01            NaN           NaN  \n",
      "\n",
      "[273 rows x 7 columns], '_3':                   date  co  co_prod  co_domestic  ca_canola_crush  \\\n",
      "date                                                                \n",
      "2000-01-01  2000-01-01 NaN      NaN          NaN          273.365   \n",
      "2000-02-01  2000-02-01 NaN      NaN          NaN          231.914   \n",
      "2000-03-01  2000-03-01 NaN      NaN          NaN          301.705   \n",
      "2000-04-01  2000-04-01 NaN      NaN          NaN          205.655   \n",
      "2000-05-01  2000-05-01 NaN      NaN          NaN          265.540   \n",
      "\n",
      "            ca_co_exports  cent_ill_sbo  \n",
      "date                                     \n",
      "2000-01-01         78.335         15.56  \n",
      "2000-02-01         98.451         15.09  \n",
      "2000-03-01         87.800         16.22  \n",
      "2000-04-01         81.074         17.52  \n",
      "2000-05-01         61.784         16.75  , '_i3': 'raw.head()', '_i4': 'mn.matrix(raw)', '_4': <matplotlib.axes._subplots.AxesSubplot object at 0x0000016336F41988>, '_5': '[{\"varName\": \"raw\", \"varType\": \"DataFrame\", \"varSize\": \"17472\", \"varShape\": \"273 rows x 7 cols\", \"varContent\": \"Columns: date, co, co_prod, co_domestic, ca_canola_crush, ca_co_exports, cent_ill_sbo\", \"isMatrix\": true, \"isWidget\": false}]', '_i5': 'mn.matrix(raw[raw.co.notnull()])\\ndf = raw[raw.co.notnull()]', 'df': date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "cent_ill_sbo      28.710000  \n",
      "\n",
      "[6 rows x 197 columns], '_6':                co  co_prod  co_domestic  ca_canola_crush  ca_co_exports  \\\n",
      "date                                                                      \n",
      "2004-03-01  40.39     24.0         91.0          325.247         97.685   \n",
      "2004-04-01  39.85     53.0        152.0          307.567        110.618   \n",
      "2004-05-01  38.00     56.0        108.0          288.000        105.372   \n",
      "2004-06-01  35.32     40.0         58.0          234.607         68.013   \n",
      "2004-07-01  33.98     56.0        228.0          306.664         93.408   \n",
      "\n",
      "            cent_ill_sbo  \n",
      "date                      \n",
      "2004-03-01         34.66  \n",
      "2004-04-01         34.19  \n",
      "2004-05-01         32.68  \n",
      "2004-06-01         30.08  \n",
      "2004-07-01         28.05  , '_i6': \"df = df.drop('date',axis=1)\\ndf.head()\", '_7': date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "\n",
      "[5 rows x 197 columns], '_i7': 'df = df.T\\ndf.head()', '_i8': '\\ndata_start_date = df.columns[1]\\ndata_end_date = df.columns[-1]\\n\\npred_steps = 900\\npred_length=timedelta(pred_steps)\\nprint(pred_length)\\nfirst_day = pd.to_datetime(data_start_date)\\nlast_day = pd.to_datetime(data_end_date)\\n\\nval_pred_start = last_day - pred_length + timedelta(1)\\nval_pred_end = last_day\\n\\ntrain_pred_start = val_pred_start - pred_length\\ntrain_pred_end = val_pred_start - timedelta(days=1)\\n\\nenc_length = train_pred_start - first_day\\n\\ntrain_enc_start = first_day\\ntrain_enc_end = train_enc_start + enc_length - timedelta(1)\\n\\nval_enc_start = train_enc_start + pred_length\\nval_enc_end = val_enc_start + enc_length - timedelta(1) ', 'data_start_date': datetime.date(2004, 4, 1), 'data_end_date': datetime.date(2020, 7, 1), 'pred_steps': 900, 'pred_length': datetime.timedelta(days=900), 'first_day': Timestamp('2004-04-01 00:00:00'), 'last_day': Timestamp('2020-07-01 00:00:00'), 'val_pred_start': Timestamp('2018-01-14 00:00:00'), 'val_pred_end': Timestamp('2020-07-01 00:00:00'), 'train_pred_start': Timestamp('2015-07-29 00:00:00'), 'train_pred_end': Timestamp('2018-01-13 00:00:00'), 'enc_length': Timedelta('4136 days 00:00:00'), 'train_enc_start': Timestamp('2004-04-01 00:00:00'), 'train_enc_end': Timestamp('2015-07-28 00:00:00'), 'val_enc_start': Timestamp('2006-09-18 00:00:00'), 'val_enc_end': Timestamp('2018-01-13 00:00:00'), '_i9': \"print('Train encoding:', train_enc_start, '-', train_enc_end)\\nprint('Train prediction:', train_pred_start, '-', train_pred_end, '\\\\n')\\nprint('Val encoding:', val_enc_start, '-', val_enc_end)\\nprint('Val prediction:', val_pred_start, '-', val_pred_end)\\n\\nprint('\\\\nEncoding interval:', enc_length.days)\\nprint('Prediction interval:', pred_length.days)\", '_i10': 'date_to_index = pd.Series(index=pd.Index([pd.to_datetime(c) for c in df.columns[1:]]),\\n                          data=[i for i in range(len(df.columns[1:]))])\\n\\nseries_array = df[df.columns[1:]].values\\n\\ndef get_time_block_series(series_array, date_to_index, start_date, end_date):\\n    \\n    inds = date_to_index[start_date:end_date]\\n    return series_array[:,inds]\\n\\ndef transform_series_encode(series_array):\\n    \\n    series_array = np.log(series_array)\\n    series_mean = series_array.mean(axis=1).reshape(-1,1) \\n    series_array = series_array - series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array, series_mean\\n\\ndef transform_series_decode(series_array, encode_series_mean):\\n    \\n    series_array = np.log(series_array)\\n    series_array = series_array - encode_series_mean\\n    series_array = series_array.reshape((series_array.shape[0],series_array.shape[1], 1))\\n    \\n    return series_array', 'date_to_index': 2004-04-01      0\n",
      "2004-05-01      1\n",
      "2004-06-01      2\n",
      "2004-07-01      3\n",
      "2004-08-01      4\n",
      "             ... \n",
      "2020-03-01    191\n",
      "2020-04-01    192\n",
      "2020-05-01    193\n",
      "2020-06-01    194\n",
      "2020-07-01    195\n",
      "Length: 196, dtype: int64, 'series_array': array([[ 39.85     ,  38.       ,  35.32     , ...,  32.5      ,\n",
      "         35.28     ,  41.95     ],\n",
      "       [ 53.       ,  56.       ,  40.       , ..., 162.       ,\n",
      "        106.       , 140.       ],\n",
      "       [152.       , 108.       ,  58.       , ..., 472.       ,\n",
      "        525.       , 507.       ],\n",
      "       [307.567    , 288.       , 234.607    , ..., 855.008    ,\n",
      "        864.559    , 815.       ],\n",
      "       [110.618    , 105.372    ,  68.013    , ..., 340.571679 ,\n",
      "        276.8021964, 327.7883556],\n",
      "       [ 34.19     ,  32.68     ,  30.08     , ...,  25.27     ,\n",
      "         26.61     ,  28.71     ]]), 'get_time_block_series': <function get_time_block_series at 0x000001633706F828>, 'transform_series_encode': <function transform_series_encode at 0x000001633706F438>, 'transform_series_decode': <function transform_series_decode at 0x000001633706F948>, '_i11': 'df', '_11': date             2004-03-01  2004-04-01  2004-05-01  2004-06-01  2004-07-01  \\\n",
      "co                   40.390      39.850      38.000      35.320      33.980   \n",
      "co_prod              24.000      53.000      56.000      40.000      56.000   \n",
      "co_domestic          91.000     152.000     108.000      58.000     228.000   \n",
      "ca_canola_crush     325.247     307.567     288.000     234.607     306.664   \n",
      "ca_co_exports        97.685     110.618     105.372      68.013      93.408   \n",
      "cent_ill_sbo         34.660      34.190      32.680      30.080      28.050   \n",
      "\n",
      "date             2004-08-01  2004-09-01  2004-10-01  2004-11-01  2004-12-01  \\\n",
      "co                   31.950      32.150      29.850      33.930      32.170   \n",
      "co_prod              75.000      74.000      82.000      59.000      64.000   \n",
      "co_domestic         213.000     159.000     139.000     137.000     127.000   \n",
      "ca_canola_crush     259.121     223.777     288.740     274.977     283.584   \n",
      "ca_co_exports       147.687      75.383     106.488      93.807     128.998   \n",
      "cent_ill_sbo         25.980      25.870      23.230      22.950      21.790   \n",
      "\n",
      "date             ...  2019-10-01  2019-11-01  2019-12-01  2020-01-01  \\\n",
      "co               ...   38.780000   37.580000   38.440000   38.570000   \n",
      "co_prod          ...  157.000000  127.000000  147.000000  139.000000   \n",
      "co_domestic      ...  498.000000  437.000000  482.000000  493.000000   \n",
      "ca_canola_crush  ...  882.301000  829.303000  899.331000  854.686000   \n",
      "ca_co_exports    ...  310.118426  251.207234  288.721506  311.512257   \n",
      "cent_ill_sbo     ...   30.140000   30.621000   32.270000   33.040000   \n",
      "\n",
      "date             2020-02-01  2020-03-01  2020-04-01  2020-05-01  2020-06-01  \\\n",
      "co                35.870000   33.250000   33.330000   32.500000   35.280000   \n",
      "co_prod          147.000000  161.000000  147.000000  162.000000  106.000000   \n",
      "co_domestic      401.000000  548.000000  438.000000  472.000000  525.000000   \n",
      "ca_canola_crush  812.633000  881.384000  845.459000  855.008000  864.559000   \n",
      "ca_co_exports    248.039262  338.876088  262.566916  340.571679  276.802196   \n",
      "cent_ill_sbo      30.260000   27.040000   25.690000   25.270000   26.610000   \n",
      "\n",
      "date             2020-07-01  \n",
      "co                41.950000  \n",
      "co_prod          140.000000  \n",
      "co_domestic      507.000000  \n",
      "ca_canola_crush  815.000000  \n",
      "ca_co_exports    327.788356  \n",
      "cent_ill_sbo      28.710000  \n",
      "\n",
      "[6 rows x 197 columns], '_i12': 'from keras.models import Model\\nfrom keras.layers import Input, Conv1D, Dense, Activation, Dropout, Lambda, Multiply, Add, Concatenate\\nfrom keras.optimizers import Adam', '_i13': \"# hyper-parameters\\nn_filters = 32\\nfilter_width = 2\\ndilation_rates = [2**i for i in range(7)] * 2 \\n\\n# define an input history series and pass it through a stack of dilated causal convolution blocks\\nhistory_seq = Input(shape=(None, 1))\\nx = history_seq\\n\\nskips = []\\nfor dilation_rate in dilation_rates:\\n    \\n    # preprocessing - equivalent to time-distributed dense\\n    x = Conv1D(16, 1, padding='same', activation='relu')(x) \\n    \\n    # filter\\n    x_f = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # gate\\n    x_g = Conv1D(filters=n_filters,\\n                 kernel_size=filter_width, \\n                 padding='causal',\\n                 dilation_rate=dilation_rate)(x)\\n    \\n    # combine filter and gating branches\\n    z = Multiply()([Activation('tanh')(x_f),\\n                    Activation('sigmoid')(x_g)])\\n    \\n    # postprocessing - equivalent to time-distributed dense\\n    z = Conv1D(16, 1, padding='same', activation='relu')(z)\\n    \\n    # residual connection\\n    x = Add()([x, z])    \\n    \\n    # collect skip connections\\n    skips.append(z)\\n\\n# add all skip connection outputs \\nout = Activation('relu')(Add()(skips))\\n\\n# final time-distributed dense layers \\nout = Conv1D(128, 1, padding='same')(out)\\nout = Activation('relu')(out)\\nout = Dropout(.2)(out)\\nout = Conv1D(1, 1, padding='same')(out)\\n\\n# extract training target at end\\ndef slice(x, seq_length):\\n    return x[:,-seq_length:,:]\\n\\npred_seq_train = Lambda(slice, arguments={'seq_length':30})(out)\\n\\nmodel = Model(history_seq, pred_seq_train)\\nmodel.compile(Adam(), loss='mean_absolute_error')\", 'n_filters': 32, 'filter_width': 2, 'dilation_rates': [1, 2, 4, 8, 16, 32, 64, 1, 2, 4, 8, 16, 32, 64], 'history_seq': <tf.Tensor 'input_1:0' shape=(None, None, 1) dtype=float32>, 'x': <tf.Tensor 'add_13/add:0' shape=(None, None, 16) dtype=float32>, 'skips': [<tf.Tensor 'conv1d_3/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_7/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_11/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_15/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_19/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_23/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_27/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_31/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_35/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_39/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_43/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_47/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_51/Relu:0' shape=(None, None, 16) dtype=float32>, <tf.Tensor 'conv1d_55/Relu:0' shape=(None, None, 16) dtype=float32>], 'dilation_rate': 64, 'x_f': <tf.Tensor 'conv1d_53/BiasAdd:0' shape=(None, None, 32) dtype=float32>, 'x_g': <tf.Tensor 'conv1d_54/BiasAdd:0' shape=(None, None, 32) dtype=float32>, 'z': <tf.Tensor 'conv1d_55/Relu:0' shape=(None, None, 16) dtype=float32>, 'out': <tf.Tensor 'conv1d_57/BiasAdd:0' shape=(None, None, 1) dtype=float32>, 'slice': <function slice at 0x0000016340197B88>, 'pred_seq_train': <tf.Tensor 'lambda/strided_slice:0' shape=(None, None, 1) dtype=float32>, 'model': <tensorflow.python.keras.engine.functional.Functional object at 0x000001634025EA48>, '_i14': 'model.summary()', '_i15': 'first_n_samples = 8\\nbatch_size = 2**10\\nepochs = 100\\n\\n# sample of series from train_enc_start to train_enc_end  \\nencoder_input_data = get_time_block_series(series_array, date_to_index, \\n                                           train_enc_start, train_enc_end)[:first_n_samples]\\n\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\n\\n# sample of series from train_pred_start to train_pred_end \\ndecoder_target_data = get_time_block_series(series_array, date_to_index, \\n                                            train_pred_start, train_pred_end)[:first_n_samples]\\n\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)\\n\\n# we append a lagged history of the target series to the input data, \\n# so that we can train with teacher forcing\\nlagged_target_history = decoder_target_data[:,:-1,:1]\\nencoder_input_data = np.concatenate([encoder_input_data, lagged_target_history], axis=1)', 'first_n_samples': 8, 'batch_size': 1024, 'epochs': 100, 'encoder_input_data': array([[[-2.32190077e-01],\n",
      "        [-1.60105354e-01],\n",
      "        [-1.75120651e-01],\n",
      "        [-2.08970036e-01],\n",
      "        [-1.79669559e-01],\n",
      "        [-1.81190472e-01],\n",
      "        [-1.67334601e-01],\n",
      "        [-1.09259253e-01],\n",
      "        [-7.08196977e-02],\n",
      "        [-5.52896066e-03],\n",
      "        [-7.44609832e-03],\n",
      "        [ 8.65063080e-02],\n",
      "        [ 1.57128287e-01],\n",
      "        [ 2.17146296e-01],\n",
      "        [ 2.35876279e-01],\n",
      "        [ 3.21688900e-01],\n",
      "        [ 4.15910591e-01],\n",
      "        [ 4.43045373e-01],\n",
      "        [ 4.27708909e-01],\n",
      "        [ 4.49816797e-01],\n",
      "        [ 4.85871066e-01],\n",
      "        [ 4.55603772e-01],\n",
      "        [ 2.87988363e-01],\n",
      "        [ 1.73808792e-01],\n",
      "        [-1.28176803e-03],\n",
      "        [-1.16604387e-01],\n",
      "        [-1.89341307e-01],\n",
      "        [-1.60105354e-01],\n",
      "        [-2.43195422e-01],\n",
      "        [-2.70556910e-01],\n",
      "        [-1.60105354e-01],\n",
      "        [-7.88024063e-02],\n",
      "        [-6.92307744e-02],\n",
      "        [-1.20416639e-01],\n",
      "        [-3.81911049e-02],\n",
      "        [-1.21849988e-01],\n",
      "        [-8.04066234e-02],\n",
      "        [-1.34341402e-02],\n",
      "        [-4.67807782e-03],\n",
      "        [-6.99114324e-02],\n",
      "        [-7.26387068e-02],\n",
      "        [-5.54902722e-02],\n",
      "        [-6.29002084e-02],\n",
      "        [-1.05959698e-01],\n",
      "        [-9.63588748e-02],\n",
      "        [-2.20511689e-02],\n",
      "        [ 3.08310831e-02],\n",
      "        [ 3.53355952e-02],\n",
      "        [ 1.03633639e-01],\n",
      "        [ 1.59837581e-01],\n",
      "        [ 2.23767151e-01],\n",
      "        [ 2.51303308e-01],\n",
      "        [ 2.55901773e-01],\n",
      "        [ 2.56393214e-01],\n",
      "        [ 2.90365731e-01],\n",
      "        [ 2.75534106e-01],\n",
      "        [ 2.65684991e-01],\n",
      "        [ 2.75855391e-01],\n",
      "        [ 2.65035746e-01],\n",
      "        [ 2.56556973e-01],\n",
      "        [ 2.22243147e-01],\n",
      "        [ 2.27819841e-01],\n",
      "        [ 2.08593388e-01],\n",
      "        [ 2.07218108e-01],\n",
      "        [ 2.26808207e-01],\n",
      "        [ 2.56393214e-01],\n",
      "        [ 2.86876987e-01],\n",
      "        [ 2.45359755e-01],\n",
      "        [ 2.45028519e-01],\n",
      "        [ 3.08251366e-01],\n",
      "        [ 2.99191636e-01],\n",
      "        [ 3.07006617e-01],\n",
      "        [ 2.72799007e-01],\n",
      "        [ 2.29167096e-01],\n",
      "        [ 2.17657152e-01],\n",
      "        [ 2.39214066e-01],\n",
      "        [ 2.54590082e-01],\n",
      "        [ 2.45525331e-01],\n",
      "        [ 3.12131250e-01],\n",
      "        [ 3.07940324e-01],\n",
      "        [ 2.63898551e-01],\n",
      "        [ 1.94580530e-01],\n",
      "        [ 1.03633639e-01],\n",
      "        [ 7.98850570e-02],\n",
      "        [ 2.36227314e-02],\n",
      "        [ 5.26593727e-03],\n",
      "        [-3.66531501e-02],\n",
      "        [-8.82353532e-02],\n",
      "        [-1.32196630e-02],\n",
      "        [ 5.81579530e-02],\n",
      "        [ 8.76702267e-02],\n",
      "        [ 5.35547226e-02],\n",
      "        [ 3.34952921e-02],\n",
      "        [-2.24839757e-02],\n",
      "        [-8.75421123e-02],\n",
      "        [-1.12569731e-01],\n",
      "        [-7.97187866e-02],\n",
      "        [-1.06665829e-01],\n",
      "        [-1.34359172e-01],\n",
      "        [-1.20655388e-01],\n",
      "        [-1.48744402e-01],\n",
      "        [-1.80176273e-01],\n",
      "        [-2.64472820e-01],\n",
      "        [-2.67786825e-01],\n",
      "        [-2.27396459e-01],\n",
      "        [-2.62269570e-01],\n",
      "        [-3.49906377e-01],\n",
      "        [-4.04841509e-01],\n",
      "        [-3.72993672e-01],\n",
      "        [-4.33483853e-01],\n",
      "        [-3.52913898e-01],\n",
      "        [-3.60776049e-01],\n",
      "        [-3.03550175e-01],\n",
      "        [-2.86494616e-01],\n",
      "        [-2.45898126e-01],\n",
      "        [-2.92431030e-01],\n",
      "        [-2.70279556e-01],\n",
      "        [-3.10454690e-01],\n",
      "        [-2.15249492e-01],\n",
      "        [-1.90620897e-01],\n",
      "        [-1.51695707e-01],\n",
      "        [-1.40672938e-01],\n",
      "        [-1.34843434e-01],\n",
      "        [-1.70090459e-01],\n",
      "        [-2.06105078e-01],\n",
      "        [-2.26599752e-01],\n",
      "        [-2.50237705e-01],\n",
      "        [-2.24743234e-01],\n",
      "        [-2.38617523e-01],\n",
      "        [-1.89597094e-01],\n",
      "        [-1.62592298e-01],\n",
      "        [-1.52434897e-01],\n",
      "        [-1.69338108e-01],\n",
      "        [-1.50218966e-01],\n",
      "        [-1.80936826e-01],\n",
      "        [-1.85002905e-01]],\n",
      "\n",
      "       [[-1.15279951e-01],\n",
      "        [-4.36484716e-01],\n",
      "        [-3.49473339e-01],\n",
      "        [-2.44112823e-01],\n",
      "        [-2.95406117e-01],\n",
      "        [-1.07079140e+00],\n",
      "        [-2.95406117e-01],\n",
      "        [-2.31690303e-01],\n",
      "        [-5.65696447e-01],\n",
      "        [-2.31690303e-01],\n",
      "        [ 6.52084246e-02],\n",
      "        [ 5.59917694e-02],\n",
      "        [-3.10196075e-02],\n",
      "        [-3.49473339e-01],\n",
      "        [-2.69430631e-01],\n",
      "        [-1.60231339e-01],\n",
      "        [-2.07298850e-01],\n",
      "        [-9.88553298e-01],\n",
      "        [-2.07298850e-01],\n",
      "        [-1.48802643e-01],\n",
      "        [-4.83004731e-01],\n",
      "        [-1.48802643e-01],\n",
      "        [ 1.44545167e-01],\n",
      "        [ 1.36034477e-01],\n",
      "        [ 5.59917694e-02],\n",
      "        [-2.69430631e-01],\n",
      "        [-1.83488201e-01],\n",
      "        [-7.22625661e-02],\n",
      "        [-1.26329787e-01],\n",
      "        [-9.12567391e-01],\n",
      "        [-1.26329787e-01],\n",
      "        [-6.17912662e-02],\n",
      "        [-3.92032953e-01],\n",
      "        [-6.17912662e-02],\n",
      "        [ 2.33672947e-01],\n",
      "        [ 2.18047629e-01],\n",
      "        [ 2.78208925e-02],\n",
      "        [-2.95406117e-01],\n",
      "        [-2.07298850e-01],\n",
      "        [-1.04350881e-01],\n",
      "        [-1.48802643e-01],\n",
      "        [-9.37260004e-01],\n",
      "        [-1.48802643e-01],\n",
      "        [-9.35399645e-02],\n",
      "        [-4.21446838e-01],\n",
      "        [-9.35399645e-02],\n",
      "        [ 2.02174280e-01],\n",
      "        [ 1.94142108e-01],\n",
      "        [ 9.23594136e-02],\n",
      "        [-2.44112823e-01],\n",
      "        [-1.48802643e-01],\n",
      "        [-5.14284792e-02],\n",
      "        [-9.35399645e-02],\n",
      "        [-8.88469839e-01],\n",
      "        [-9.35399645e-02],\n",
      "        [-3.10196075e-02],\n",
      "        [-3.63459581e-01],\n",
      "        [-3.10196075e-02],\n",
      "        [ 2.64209671e-01],\n",
      "        [ 2.49057866e-01],\n",
      "        [ 5.59917694e-02],\n",
      "        [-2.69430631e-01],\n",
      "        [-1.83488201e-01],\n",
      "        [-8.28446754e-02],\n",
      "        [-1.26329787e-01],\n",
      "        [-9.12567391e-01],\n",
      "        [-1.26329787e-01],\n",
      "        [-6.17912662e-02],\n",
      "        [-4.06631753e-01],\n",
      "        [-6.17912662e-02],\n",
      "        [ 2.25890806e-01],\n",
      "        [ 2.18047629e-01],\n",
      "        [ 2.02174280e-01],\n",
      "        [-1.26329787e-01],\n",
      "        [-4.11719790e-02],\n",
      "        [ 6.52084246e-02],\n",
      "        [ 1.82514415e-02],\n",
      "        [-7.75991856e-01],\n",
      "        [ 1.82514415e-02],\n",
      "        [ 8.33907436e-02],\n",
      "        [-2.56691605e-01],\n",
      "        [ 8.33907436e-02],\n",
      "        [ 3.77806848e-01],\n",
      "        [ 3.64293129e-01],\n",
      "        [ 4.04298464e-01],\n",
      "        [ 8.33907436e-02],\n",
      "        [ 1.61352285e-01],\n",
      "        [ 2.71700342e-01],\n",
      "        [ 2.25890806e-01],\n",
      "        [-5.65696447e-01],\n",
      "        [ 2.25890806e-01],\n",
      "        [ 2.86515428e-01],\n",
      "        [-5.14284792e-02],\n",
      "        [ 2.86515428e-01],\n",
      "        [ 5.83346695e-01],\n",
      "        [ 5.72357574e-01],\n",
      "        [ 5.44344537e-01],\n",
      "        [ 2.18047629e-01],\n",
      "        [ 3.01114227e-01],\n",
      "        [ 4.10813145e-01],\n",
      "        [ 3.64293129e-01],\n",
      "        [-4.21446838e-01],\n",
      "        [ 3.64293129e-01],\n",
      "        [-6.17912662e-02],\n",
      "        [-1.37503088e-01],\n",
      "        [ 2.79135321e-01],\n",
      "        [ 1.61352285e-01],\n",
      "        [ 4.30106348e-01],\n",
      "        [-2.19420210e-01],\n",
      "        [ 5.59917694e-02],\n",
      "        [ 2.86515428e-01],\n",
      "        [ 2.10142449e-01],\n",
      "        [ 1.10058991e-01],\n",
      "        [ 1.86044898e-01],\n",
      "        [ 1.61352285e-01],\n",
      "        [ 9.23594136e-02],\n",
      "        [ 5.38646516e-01],\n",
      "        [ 4.61456878e-01],\n",
      "        [ 3.57467164e-01],\n",
      "        [ 5.83346695e-01],\n",
      "        [ 5.50010275e-01],\n",
      "        [ 5.55644093e-01],\n",
      "        [ 3.84495836e-01],\n",
      "        [ 3.91140379e-01],\n",
      "        [ 3.15502965e-01],\n",
      "        [ 4.23716550e-01],\n",
      "        [ 3.22620433e-01],\n",
      "        [-9.35399645e-02],\n",
      "        [ 3.01114227e-01],\n",
      "        [ 2.79135321e-01],\n",
      "        [ 2.18047629e-01],\n",
      "        [ 4.79806016e-01],\n",
      "        [ 4.23716550e-01],\n",
      "        [ 2.41394993e-01],\n",
      "        [ 3.71072816e-01],\n",
      "        [ 2.86515428e-01]],\n",
      "\n",
      "       [[-2.21487742e-01],\n",
      "        [-1.37074376e+00],\n",
      "        [-6.33144821e-01],\n",
      "        [-5.96555373e-01],\n",
      "        [-7.17336912e-01],\n",
      "        [-1.50985657e+00],\n",
      "        [-3.39270778e-01],\n",
      "        [-6.77596583e-01],\n",
      "        [-1.03241796e+00],\n",
      "        [-4.11244278e-01],\n",
      "        [-4.62275758e-01],\n",
      "        [-2.25611459e-01],\n",
      "        [-6.77596583e-01],\n",
      "        [ 2.20231119e-02],\n",
      "        [-6.33144821e-01],\n",
      "        [ 2.71902820e-01],\n",
      "        [-3.43911157e-01],\n",
      "        [-4.94193361e-01],\n",
      "        [ 1.87920913e-02],\n",
      "        [-2.59228070e-01],\n",
      "        [-4.21244361e-01],\n",
      "        [-6.02561397e-01],\n",
      "        [ 1.68773203e-01],\n",
      "        [-4.36434526e-01],\n",
      "        [-8.33374038e-02],\n",
      "        [ 3.80234532e-02],\n",
      "        [-2.46489044e-01],\n",
      "        [-3.34651832e-01],\n",
      "        [-3.62691052e-01],\n",
      "        [-3.43911157e-01],\n",
      "        [-3.91539206e-01],\n",
      "        [-2.67811814e-01],\n",
      "        [-5.90585206e-01],\n",
      "        [-3.25477456e-01],\n",
      "        [-1.41056122e-02],\n",
      "        [-4.31345457e-01],\n",
      "        [ 5.06419172e-02],\n",
      "        [-7.97595824e-02],\n",
      "        [-3.02903134e-01],\n",
      "        [-2.25611459e-01],\n",
      "        [-5.61257591e-01],\n",
      "        [-4.46691027e-01],\n",
      "        [-7.61945163e-02],\n",
      "        [-2.33910262e-01],\n",
      "        [-3.96429192e-01],\n",
      "        [-3.91539206e-01],\n",
      "        [-7.61945163e-02],\n",
      "        [-2.46489044e-01],\n",
      "        [-1.46204682e-01],\n",
      "        [-2.85203557e-01],\n",
      "        [-5.55493886e-01],\n",
      "        [ 1.20261551e-01],\n",
      "        [-7.03913892e-01],\n",
      "        [ 2.84540022e-02],\n",
      "        [-1.27300527e-01],\n",
      "        [ 3.23321734e-01],\n",
      "        [ 9.03591634e-03],\n",
      "        [ 4.25335367e-01],\n",
      "        [ 3.08898407e-01],\n",
      "        [ 1.11450922e-01],\n",
      "        [ 2.74412231e-01],\n",
      "        [ 9.95813462e-02],\n",
      "        [ 1.74328773e-01],\n",
      "        [ 6.92759967e-02],\n",
      "        [-7.97595824e-02],\n",
      "        [-1.74556991e-02],\n",
      "        [ 1.20261551e-01],\n",
      "        [-3.77953833e-02],\n",
      "        [ 4.75021972e-02],\n",
      "        [-1.34819360e-01],\n",
      "        [ 1.26092472e-01],\n",
      "        [-9.05316794e-02],\n",
      "        [ 1.63186596e-01],\n",
      "        [-1.08747119e-01],\n",
      "        [-1.08747119e-01],\n",
      "        [-9.05316794e-02],\n",
      "        [-7.61945163e-02],\n",
      "        [-3.11871804e-01],\n",
      "        [ 1.20261551e-01],\n",
      "        [-4.46682626e-02],\n",
      "        [-7.26421147e-02],\n",
      "        [ 6.92759967e-02],\n",
      "        [ 1.65983801e-01],\n",
      "        [ 8.15085651e-02],\n",
      "        [ 4.11930280e-02],\n",
      "        [ 2.96717989e-01],\n",
      "        [ 8.15085651e-02],\n",
      "        [ 1.51918871e-01],\n",
      "        [-1.41056122e-02],\n",
      "        [-2.13290975e-01],\n",
      "        [ 2.89337881e-01],\n",
      "        [ 2.61801724e-01],\n",
      "        [ 2.99165970e-01],\n",
      "        [ 3.32822993e-01],\n",
      "        [ 5.58327821e-01],\n",
      "        [ 3.83525097e-01],\n",
      "        [ 7.13556087e-01],\n",
      "        [ 3.20932247e-01],\n",
      "        [ 2.20345010e-01],\n",
      "        [ 2.54158374e-01],\n",
      "        [ 1.43383969e-01],\n",
      "        [ 9.03591634e-03],\n",
      "        [ 3.90244047e-01],\n",
      "        [-3.77953833e-02],\n",
      "        [ 4.23177868e-01],\n",
      "        [ 3.69950227e-01],\n",
      "        [ 4.81894942e-01],\n",
      "        [ 3.16136075e-01],\n",
      "        [ 3.11316788e-01],\n",
      "        [ 2.54158374e-01],\n",
      "        [ 2.01652877e-01],\n",
      "        [ 3.13729335e-01],\n",
      "        [ 2.12376840e-01],\n",
      "        [ 3.06474164e-01],\n",
      "        [ 4.83929531e-01],\n",
      "        [ 3.53876403e-01],\n",
      "        [ 5.71448909e-01],\n",
      "        [ 4.92026741e-01],\n",
      "        [ 2.69387095e-01],\n",
      "        [ 6.43293081e-01],\n",
      "        [ 5.21820405e-01],\n",
      "        [ 4.31780072e-01],\n",
      "        [ 4.65467468e-01],\n",
      "        [ 5.91726101e-01],\n",
      "        [ 3.72225541e-01],\n",
      "        [ 2.89337881e-01],\n",
      "        [ 5.27674080e-01],\n",
      "        [ 4.25335367e-01],\n",
      "        [ 4.77813304e-01],\n",
      "        [ 4.52967305e-01],\n",
      "        [ 5.52651363e-01],\n",
      "        [ 5.13961818e-01],\n",
      "        [ 6.62177762e-01],\n",
      "        [ 4.57151412e-01],\n",
      "        [ 4.12319998e-01],\n",
      "        [ 4.36053583e-01]],\n",
      "\n",
      "       [[-4.51480983e-01],\n",
      "        [-4.51413270e-01],\n",
      "        [-4.28779154e-01],\n",
      "        [-5.20020620e-01],\n",
      "        [-6.82025845e-01],\n",
      "        [-5.86866137e-01],\n",
      "        [-5.51322609e-01],\n",
      "        [-5.42269127e-01],\n",
      "        [-5.52030292e-01],\n",
      "        [-5.30271750e-01],\n",
      "        [-4.38004613e-01],\n",
      "        [-4.50293601e-01],\n",
      "        [-3.75153857e-01],\n",
      "        [-3.39709081e-01],\n",
      "        [-3.11483003e-01],\n",
      "        [-3.64841080e-01],\n",
      "        [-4.05231443e-01],\n",
      "        [-3.09961606e-01],\n",
      "        [-4.56547785e-01],\n",
      "        [-4.22570134e-01],\n",
      "        [-4.14448833e-01],\n",
      "        [-4.10570840e-01],\n",
      "        [-5.20327223e-01],\n",
      "        [-3.44244373e-01],\n",
      "        [-2.53052144e-01],\n",
      "        [-3.29369477e-01],\n",
      "        [-2.75781962e-01],\n",
      "        [-3.48814217e-01],\n",
      "        [-3.88774940e-01],\n",
      "        [-2.78183519e-01],\n",
      "        [-3.68800406e-01],\n",
      "        [-4.66024879e-01],\n",
      "        [-4.38916051e-01],\n",
      "        [-3.22774349e-01],\n",
      "        [-4.28015196e-01],\n",
      "        [-4.22211370e-01],\n",
      "        [-5.00303312e-01],\n",
      "        [-3.09974965e-01],\n",
      "        [-3.65696663e-01],\n",
      "        [-2.25251939e-01],\n",
      "        [-2.75116028e-01],\n",
      "        [-8.20070923e-02],\n",
      "        [-1.54349770e-01],\n",
      "        [-1.65705976e-01],\n",
      "        [-1.23220473e-01],\n",
      "        [-2.60337368e-02],\n",
      "        [-1.50752332e-01],\n",
      "        [-1.03975513e-02],\n",
      "        [ 7.73379730e-02],\n",
      "        [ 7.84782250e-02],\n",
      "        [ 8.13981516e-02],\n",
      "        [-3.66592455e-03],\n",
      "        [-4.08317111e-02],\n",
      "        [ 1.29924964e-01],\n",
      "        [ 6.42878958e-02],\n",
      "        [-9.94419682e-03],\n",
      "        [ 3.65211176e-02],\n",
      "        [ 7.79164191e-02],\n",
      "        [-1.36232327e-01],\n",
      "        [ 1.46737303e-01],\n",
      "        [ 1.44205918e-01],\n",
      "        [ 1.66115523e-01],\n",
      "        [ 2.76875534e-01],\n",
      "        [ 2.21276095e-01],\n",
      "        [ 1.48073268e-01],\n",
      "        [ 2.69085303e-01],\n",
      "        [ 1.85045556e-01],\n",
      "        [ 2.56549145e-02],\n",
      "        [-6.29705366e-02],\n",
      "        [ 1.36831189e-01],\n",
      "        [-4.08051738e-02],\n",
      "        [ 2.13258731e-01],\n",
      "        [ 2.63701342e-01],\n",
      "        [ 1.41829673e-01],\n",
      "        [ 2.55338419e-01],\n",
      "        [ 9.44529424e-02],\n",
      "        [ 3.39595895e-02],\n",
      "        [ 1.50222283e-01],\n",
      "        [ 1.24273023e-01],\n",
      "        [-1.36757957e-01],\n",
      "        [-6.49175623e-02],\n",
      "        [-1.74359996e-02],\n",
      "        [-3.55818860e-01],\n",
      "        [ 9.10146562e-02],\n",
      "        [ 2.25339019e-01],\n",
      "        [ 1.85942525e-01],\n",
      "        [ 2.30836496e-01],\n",
      "        [ 1.57127549e-01],\n",
      "        [ 5.23716152e-02],\n",
      "        [ 1.91757344e-01],\n",
      "        [ 1.29098583e-01],\n",
      "        [ 1.23173444e-01],\n",
      "        [ 1.19076187e-01],\n",
      "        [ 2.88306526e-01],\n",
      "        [ 8.20681333e-02],\n",
      "        [ 2.07335446e-01],\n",
      "        [ 1.88333224e-01],\n",
      "        [ 5.60488918e-02],\n",
      "        [ 2.27937083e-01],\n",
      "        [ 2.45182717e-01],\n",
      "        [ 8.80760600e-02],\n",
      "        [ 2.71696263e-01],\n",
      "        [ 1.60132525e-01],\n",
      "        [ 1.13231187e-01],\n",
      "        [ 2.16876394e-01],\n",
      "        [ 3.09731973e-01],\n",
      "        [ 1.44109212e-01],\n",
      "        [ 1.81253451e-01],\n",
      "        [ 3.43874551e-01],\n",
      "        [ 3.03362818e-01],\n",
      "        [ 3.77330639e-01],\n",
      "        [ 2.92725310e-01],\n",
      "        [ 3.30671377e-01],\n",
      "        [ 3.86775333e-01],\n",
      "        [ 1.83797250e-01],\n",
      "        [ 3.26739799e-01],\n",
      "        [ 3.19979025e-01],\n",
      "        [ 4.37805700e-01],\n",
      "        [ 2.65334907e-01],\n",
      "        [ 4.23359400e-01],\n",
      "        [ 4.60480185e-01],\n",
      "        [ 4.55803877e-01],\n",
      "        [ 4.88365729e-01],\n",
      "        [ 4.47602105e-01],\n",
      "        [ 3.88035091e-01],\n",
      "        [ 4.76754427e-01],\n",
      "        [ 3.81797961e-01],\n",
      "        [ 3.17536938e-01],\n",
      "        [ 3.59609274e-01],\n",
      "        [ 3.81016414e-01],\n",
      "        [ 2.09027080e-01],\n",
      "        [ 3.83269732e-01],\n",
      "        [ 5.34665878e-01],\n",
      "        [ 4.57041700e-01],\n",
      "        [ 4.78509598e-01],\n",
      "        [ 3.98645901e-01]],\n",
      "\n",
      "       [[-4.59695737e-01],\n",
      "        [-5.69693541e-01],\n",
      "        [-5.15696084e-01],\n",
      "        [-4.14867635e-01],\n",
      "        [-7.51322926e-01],\n",
      "        [-6.60037636e-01],\n",
      "        [-4.88716895e-01],\n",
      "        [-4.78488692e-01],\n",
      "        [-1.82086288e-01],\n",
      "        [-3.52765356e-01],\n",
      "        [-7.14628292e-01],\n",
      "        [-5.57160632e-01],\n",
      "        [-5.18755912e-01],\n",
      "        [-5.43992013e-01],\n",
      "        [-7.16711507e-01],\n",
      "        [-2.79652636e-01],\n",
      "        [-5.47352582e-01],\n",
      "        [-3.48030867e-01],\n",
      "        [-2.43371960e-01],\n",
      "        [-4.03653478e-01],\n",
      "        [-8.52967102e-01],\n",
      "        [-3.72425940e-01],\n",
      "        [-3.29236155e-01],\n",
      "        [-7.55244966e-01],\n",
      "        [-2.96355265e-01],\n",
      "        [-1.75383361e-02],\n",
      "        [-7.86966391e-01],\n",
      "        [-4.55080834e-01],\n",
      "        [-4.40692852e-01],\n",
      "        [-1.17470148e-01],\n",
      "        [-1.11309295e-01],\n",
      "        [-4.01402252e-01],\n",
      "        [-2.46674936e-01],\n",
      "        [-2.70773710e-01],\n",
      "        [-3.51929631e-01],\n",
      "        [-3.40027036e-01],\n",
      "        [-2.50765126e-01],\n",
      "        [-4.49477938e-01],\n",
      "        [-5.64809153e-01],\n",
      "        [-2.15818866e-01],\n",
      "        [-2.95783462e-01],\n",
      "        [ 4.47828604e-02],\n",
      "        [ 1.19916093e-01],\n",
      "        [-1.61725698e-01],\n",
      "        [ 1.71430803e-02],\n",
      "        [ 1.93584715e-01],\n",
      "        [ 6.93952108e-02],\n",
      "        [-2.35266337e-03],\n",
      "        [ 2.88575858e-01],\n",
      "        [ 1.12248219e-01],\n",
      "        [ 2.39982955e-01],\n",
      "        [ 1.52052786e-01],\n",
      "        [-1.62647030e-01],\n",
      "        [ 3.32162578e-01],\n",
      "        [ 1.83128218e-01],\n",
      "        [-7.34012075e-03],\n",
      "        [ 1.29213706e-01],\n",
      "        [ 1.03113854e-01],\n",
      "        [ 1.53652021e-01],\n",
      "        [ 9.13806999e-02],\n",
      "        [ 3.26825583e-01],\n",
      "        [ 2.53718570e-01],\n",
      "        [ 3.68864632e-01],\n",
      "        [ 2.22151788e-01],\n",
      "        [ 1.81561470e-01],\n",
      "        [ 2.35363642e-01],\n",
      "        [ 4.43926811e-01],\n",
      "        [ 4.44992385e-02],\n",
      "        [ 7.36495686e-03],\n",
      "        [ 2.87023245e-01],\n",
      "        [ 1.02957371e-01],\n",
      "        [ 3.47234006e-01],\n",
      "        [ 2.90218163e-01],\n",
      "        [ 1.08956806e-01],\n",
      "        [ 3.98716685e-01],\n",
      "        [ 8.29339111e-02],\n",
      "        [ 2.44585409e-01],\n",
      "        [ 2.35549356e-01],\n",
      "        [ 1.26244116e-01],\n",
      "        [ 6.45545377e-02],\n",
      "        [-2.13370800e-01],\n",
      "        [ 2.34323920e-02],\n",
      "        [-3.52080806e-01],\n",
      "        [-1.98301908e-01],\n",
      "        [ 3.27027345e-01],\n",
      "        [ 1.29179284e-01],\n",
      "        [ 1.22934196e-01],\n",
      "        [ 1.47384551e-01],\n",
      "        [ 1.60895710e-01],\n",
      "        [ 1.48832155e-01],\n",
      "        [ 1.53546445e-01],\n",
      "        [ 1.36772352e-02],\n",
      "        [ 2.06416945e-01],\n",
      "        [ 9.58647838e-02],\n",
      "        [ 1.32743072e-01],\n",
      "        [-1.30397663e-01],\n",
      "        [ 2.91000660e-01],\n",
      "        [ 8.87880973e-02],\n",
      "        [-1.09459676e-01],\n",
      "        [ 5.74421659e-02],\n",
      "        [-2.45100718e-02],\n",
      "        [ 1.80095084e-01],\n",
      "        [ 1.19245820e-01],\n",
      "        [ 1.94045691e-01],\n",
      "        [ 1.97303337e-01],\n",
      "        [ 3.07128603e-01],\n",
      "        [-5.39264391e-02],\n",
      "        [ 1.10941968e-01],\n",
      "        [ 3.02284800e-01],\n",
      "        [ 3.75444314e-01],\n",
      "        [ 3.32640150e-01],\n",
      "        [ 8.28051450e-02],\n",
      "        [ 5.32039615e-01],\n",
      "        [ 1.89213335e-01],\n",
      "        [ 2.26645052e-01],\n",
      "        [ 2.98522328e-01],\n",
      "        [ 1.84464541e-01],\n",
      "        [ 3.51806358e-01],\n",
      "        [ 1.93506328e-01],\n",
      "        [ 4.21371634e-01],\n",
      "        [ 4.55834411e-01],\n",
      "        [ 3.64999275e-01],\n",
      "        [ 3.86937309e-01],\n",
      "        [ 3.82164285e-01],\n",
      "        [ 3.86070488e-01],\n",
      "        [ 3.77107438e-01],\n",
      "        [ 4.51696930e-01],\n",
      "        [ 4.91164343e-01],\n",
      "        [ 2.69206525e-01],\n",
      "        [ 2.98949841e-01],\n",
      "        [ 9.96825213e-02],\n",
      "        [ 1.63567160e-01],\n",
      "        [ 5.98102757e-01],\n",
      "        [ 4.24630349e-01],\n",
      "        [ 3.39470403e-01],\n",
      "        [ 2.93706606e-01]],\n",
      "\n",
      "       [[-4.35200861e-01],\n",
      "        [-3.26377208e-01],\n",
      "        [-3.25653881e-01],\n",
      "        [-3.12722666e-01],\n",
      "        [-2.80416486e-01],\n",
      "        [-2.53148266e-01],\n",
      "        [-2.09720390e-01],\n",
      "        [-1.52168550e-01],\n",
      "        [-1.18986608e-01],\n",
      "        [-6.93706976e-02],\n",
      "        [-9.40143466e-02],\n",
      "        [-3.77006957e-02],\n",
      "        [-5.42692518e-03],\n",
      "        [ 1.08089219e-01],\n",
      "        [ 1.64570532e-01],\n",
      "        [ 2.61771186e-01],\n",
      "        [ 3.91780208e-01],\n",
      "        [ 4.02135719e-01],\n",
      "        [ 3.90014359e-01],\n",
      "        [ 4.19446174e-01],\n",
      "        [ 4.88404722e-01],\n",
      "        [ 4.57663096e-01],\n",
      "        [ 2.81861369e-01],\n",
      "        [ 1.84954799e-01],\n",
      "        [-7.61085108e-02],\n",
      "        [-1.94067618e-01],\n",
      "        [-2.68053691e-01],\n",
      "        [-1.74917763e-01],\n",
      "        [-2.80762088e-01],\n",
      "        [-3.05255965e-01],\n",
      "        [-1.56432948e-01],\n",
      "        [-6.04569895e-02],\n",
      "        [-7.16115949e-02],\n",
      "        [-2.09076682e-01],\n",
      "        [-1.28440150e-01],\n",
      "        [-2.12945159e-01],\n",
      "        [-1.44598491e-01],\n",
      "        [-4.58662283e-02],\n",
      "        [-3.98716599e-02],\n",
      "        [-9.37276083e-02],\n",
      "        [-9.91897463e-02],\n",
      "        [-5.13471957e-02],\n",
      "        [-3.17547322e-02],\n",
      "        [-7.86469412e-02],\n",
      "        [-1.05551827e-01],\n",
      "        [-8.82951432e-02],\n",
      "        [-1.94353477e-02],\n",
      "        [ 2.32906090e-02],\n",
      "        [ 1.39002869e-01],\n",
      "        [ 2.17611634e-01],\n",
      "        [ 2.96134756e-01],\n",
      "        [ 3.40375478e-01],\n",
      "        [ 3.47224186e-01],\n",
      "        [ 3.44638296e-01],\n",
      "        [ 3.91250780e-01],\n",
      "        [ 3.81316336e-01],\n",
      "        [ 3.73979809e-01],\n",
      "        [ 3.64596846e-01],\n",
      "        [ 3.50539106e-01],\n",
      "        [ 3.64052825e-01],\n",
      "        [ 3.00396677e-01],\n",
      "        [ 2.94774873e-01],\n",
      "        [ 2.69776031e-01],\n",
      "        [ 2.85988328e-01],\n",
      "        [ 3.12501734e-01],\n",
      "        [ 3.32731179e-01],\n",
      "        [ 3.60964441e-01],\n",
      "        [ 2.80087445e-01],\n",
      "        [ 2.39010601e-01],\n",
      "        [ 3.04832984e-01],\n",
      "        [ 3.18025031e-01],\n",
      "        [ 3.39818116e-01],\n",
      "        [ 2.52485693e-01],\n",
      "        [ 1.88852596e-01],\n",
      "        [ 2.07904868e-01],\n",
      "        [ 2.43113171e-01],\n",
      "        [ 2.52891208e-01],\n",
      "        [ 2.38393762e-01],\n",
      "        [ 2.51877112e-01],\n",
      "        [ 2.52485693e-01],\n",
      "        [ 2.22220902e-01],\n",
      "        [ 1.65234616e-01],\n",
      "        [ 9.98548472e-02],\n",
      "        [ 9.48814800e-02],\n",
      "        [ 3.47019158e-02],\n",
      "        [ 3.26827329e-02],\n",
      "        [-1.78396027e-02],\n",
      "        [-9.17227386e-02],\n",
      "        [-3.17547322e-02],\n",
      "        [ 6.35309501e-02],\n",
      "        [ 8.89283727e-02],\n",
      "        [ 6.00953639e-02],\n",
      "        [ 3.92302254e-02],\n",
      "        [-1.86371569e-02],\n",
      "        [-8.91509412e-02],\n",
      "        [-1.19574844e-01],\n",
      "        [-1.16343823e-01],\n",
      "        [-1.35589421e-01],\n",
      "        [-1.62556666e-01],\n",
      "        [-1.69645616e-01],\n",
      "        [-1.93433905e-01],\n",
      "        [-2.15208700e-01],\n",
      "        [-2.07469223e-01],\n",
      "        [-1.59796352e-01],\n",
      "        [-1.27253558e-01],\n",
      "        [-1.94384626e-01],\n",
      "        [-2.82838214e-01],\n",
      "        [-3.71141479e-01],\n",
      "        [-3.44632553e-01],\n",
      "        [-3.71519908e-01],\n",
      "        [-2.53820987e-01],\n",
      "        [-2.82145693e-01],\n",
      "        [-2.51468441e-01],\n",
      "        [-2.16180360e-01],\n",
      "        [-1.65940764e-01],\n",
      "        [-2.19426063e-01],\n",
      "        [-2.32844690e-01],\n",
      "        [-2.87003440e-01],\n",
      "        [-2.04902651e-01],\n",
      "        [-1.80217853e-01],\n",
      "        [-1.23406831e-01],\n",
      "        [-1.04102341e-01],\n",
      "        [-7.41386214e-02],\n",
      "        [-1.31710556e-01],\n",
      "        [-1.79905305e-01],\n",
      "        [-2.16180360e-01],\n",
      "        [-2.58880873e-01],\n",
      "        [-2.24641198e-01],\n",
      "        [-2.20076469e-01],\n",
      "        [-1.54603122e-01],\n",
      "        [-1.43995354e-01],\n",
      "        [-1.40684591e-01],\n",
      "        [-1.69027186e-01],\n",
      "        [-1.36187507e-01],\n",
      "        [-1.71503201e-01],\n",
      "        [-1.92167681e-01]]]), 'encode_series_mean': array([[3.85546377],\n",
      "       [4.62613946],\n",
      "       [5.71454919],\n",
      "       [6.2349738 ],\n",
      "       [5.1857641 ],\n",
      "       [3.64564121]]), 'decoder_target_data': array([[[-0.20610508],\n",
      "        [-0.21315196],\n",
      "        [-0.22845972],\n",
      "        [-0.23539864],\n",
      "        [-0.24076922],\n",
      "        [-0.23781183],\n",
      "        [-0.22209703],\n",
      "        [-0.23861752],\n",
      "        [-0.18806335],\n",
      "        [-0.20636519],\n",
      "        [-0.19010886],\n",
      "        [-0.19215857],\n",
      "        [-0.19781702],\n",
      "        [-0.23219008],\n",
      "        [-0.28339907],\n",
      "        [-0.3006873 ],\n",
      "        [-0.28311814],\n",
      "        [-0.28621281],\n",
      "        [-0.25432323],\n",
      "        [-0.23513086],\n",
      "        [-0.19755912],\n",
      "        [-0.22899178],\n",
      "        [-0.20636519],\n",
      "        [-0.202989  ],\n",
      "        [-0.27556248],\n",
      "        [-0.35140901],\n",
      "        [-0.34900588],\n",
      "        [-0.37422368],\n",
      "        [-0.29214754],\n",
      "        [-0.11898534]],\n",
      "\n",
      "       [[ 0.22589081],\n",
      "        [ 0.31550296],\n",
      "        [ 0.24905787],\n",
      "        [ 0.11879267],\n",
      "        [ 0.24139499],\n",
      "        [ 0.38449584],\n",
      "        [ 0.30833448],\n",
      "        [ 0.39774106],\n",
      "        [ 0.35746716],\n",
      "        [ 0.27170034],\n",
      "        [ 0.27170034],\n",
      "        [ 0.28651543],\n",
      "        [ 0.12745073],\n",
      "        [ 0.1860449 ],\n",
      "        [ 0.30833448],\n",
      "        [ 0.10124836],\n",
      "        [ 0.05599177],\n",
      "        [ 0.17788159],\n",
      "        [ 0.21014245],\n",
      "        [ 0.27170034],\n",
      "        [ 0.43010635],\n",
      "        [ 0.21804763],\n",
      "        [ 0.36429313],\n",
      "        [ 0.30833448],\n",
      "        [ 0.36429313],\n",
      "        [ 0.45526491],\n",
      "        [ 0.36429313],\n",
      "        [ 0.46145688],\n",
      "        [ 0.03729964],\n",
      "        [ 0.31550296]],\n",
      "\n",
      "       [[ 0.56958498],\n",
      "        [ 0.33518427],\n",
      "        [ 0.19081266],\n",
      "        [ 0.26686503],\n",
      "        [ 0.46546747],\n",
      "        [ 0.43605358],\n",
      "        [ 0.48392953],\n",
      "        [ 0.34223483],\n",
      "        [ 0.37449569],\n",
      "        [ 0.29671799],\n",
      "        [ 0.2334858 ],\n",
      "        [ 0.41884886],\n",
      "        [ 0.20165288],\n",
      "        [ 0.35618854],\n",
      "        [ 0.43605358],\n",
      "        [ 0.3538764 ],\n",
      "        [ 0.38800941],\n",
      "        [ 0.47985621],\n",
      "        [ 0.41884886],\n",
      "        [ 0.40134294],\n",
      "        [ 0.49605089],\n",
      "        [ 0.36538401],\n",
      "        [ 0.46339493],\n",
      "        [ 0.48595999],\n",
      "        [ 0.27941224],\n",
      "        [ 0.5917261 ],\n",
      "        [ 0.36766972],\n",
      "        [ 0.4424298 ],\n",
      "        [ 0.54884908],\n",
      "        [ 0.51396182]],\n",
      "\n",
      "       [[ 0.28113643],\n",
      "        [ 0.47519845],\n",
      "        [ 0.43530064],\n",
      "        [ 0.40518434],\n",
      "        [ 0.37514738],\n",
      "        [ 0.496061  ],\n",
      "        [ 0.37570609],\n",
      "        [ 0.31378527],\n",
      "        [ 0.43296215],\n",
      "        [ 0.47494864],\n",
      "        [ 0.50611395],\n",
      "        [ 0.48601807],\n",
      "        [ 0.2194792 ],\n",
      "        [ 0.34765088],\n",
      "        [ 0.46075713],\n",
      "        [ 0.46883866],\n",
      "        [ 0.3631237 ],\n",
      "        [ 0.5155544 ],\n",
      "        [ 0.48618439],\n",
      "        [ 0.40838094],\n",
      "        [ 0.54755947],\n",
      "        [ 0.48561179],\n",
      "        [ 0.56667735],\n",
      "        [ 0.51576035],\n",
      "        [ 0.46530579],\n",
      "        [ 0.5465196 ],\n",
      "        [ 0.50490587],\n",
      "        [ 0.51613702],\n",
      "        [ 0.52724575],\n",
      "        [ 0.46821431]],\n",
      "\n",
      "       [[ 0.42140754],\n",
      "        [ 0.41122828],\n",
      "        [ 0.52019066],\n",
      "        [ 0.38102364],\n",
      "        [ 0.52615796],\n",
      "        [ 0.40033387],\n",
      "        [ 0.36124615],\n",
      "        [ 0.4345307 ],\n",
      "        [ 0.3619833 ],\n",
      "        [ 0.57046779],\n",
      "        [ 0.34393479],\n",
      "        [ 0.2767255 ],\n",
      "        [ 0.15415007],\n",
      "        [ 0.53459314],\n",
      "        [ 0.50407239],\n",
      "        [ 0.39077645],\n",
      "        [ 0.33775957],\n",
      "        [ 0.31676999],\n",
      "        [ 0.45610267],\n",
      "        [ 0.38184518],\n",
      "        [ 0.55119014],\n",
      "        [ 0.34051413],\n",
      "        [ 0.47969848],\n",
      "        [ 0.55567458],\n",
      "        [ 0.32782295],\n",
      "        [ 0.63987042],\n",
      "        [ 0.38474187],\n",
      "        [ 0.64486151],\n",
      "        [ 0.43753906],\n",
      "        [ 0.60660404]],\n",
      "\n",
      "       [[-0.22366129],\n",
      "        [-0.23515378],\n",
      "        [-0.25449416],\n",
      "        [-0.26464653],\n",
      "        [-0.3027794 ],\n",
      "        [-0.34205665],\n",
      "        [-0.32782543],\n",
      "        [-0.32312635],\n",
      "        [-0.28214569],\n",
      "        [-0.33181891],\n",
      "        [-0.30844916],\n",
      "        [-0.2978446 ],\n",
      "        [-0.25854275],\n",
      "        [-0.29153543],\n",
      "        [-0.31844924],\n",
      "        [-0.3524003 ],\n",
      "        [-0.30490179],\n",
      "        [-0.32493108],\n",
      "        [-0.29890001],\n",
      "        [-0.28491866],\n",
      "        [-0.23978801],\n",
      "        [-0.22395516],\n",
      "        [-0.1715032 ],\n",
      "        [-0.14792226],\n",
      "        [-0.2358145 ],\n",
      "        [-0.34832396],\n",
      "        [-0.3995394 ],\n",
      "        [-0.41602329],\n",
      "        [-0.36435412],\n",
      "        [-0.28839571]]]), 'lagged_target_history': array([[[-0.32496499],\n",
      "        [-0.37990012],\n",
      "        [-0.34805228],\n",
      "        [-0.40854246],\n",
      "        [-0.32797251],\n",
      "        [-0.33583466],\n",
      "        [-0.27860879],\n",
      "        [-0.26155323],\n",
      "        [-0.22095674],\n",
      "        [-0.26748964],\n",
      "        [-0.24533817],\n",
      "        [-0.2855133 ],\n",
      "        [-0.1903081 ],\n",
      "        [-0.16567951],\n",
      "        [-0.12675432],\n",
      "        [-0.11573155],\n",
      "        [-0.10990204],\n",
      "        [-0.14514907],\n",
      "        [-0.18116369],\n",
      "        [-0.20165836],\n",
      "        [-0.22529632],\n",
      "        [-0.19980184],\n",
      "        [-0.21367613],\n",
      "        [-0.1646557 ],\n",
      "        [-0.13765091],\n",
      "        [-0.12749351],\n",
      "        [-0.14439672],\n",
      "        [-0.12527758],\n",
      "        [-0.15599544]],\n",
      "\n",
      "       [[ 0.31681078],\n",
      "        [ 0.58556484],\n",
      "        [-0.06396172],\n",
      "        [ 0.21145026],\n",
      "        [ 0.44197392],\n",
      "        [ 0.36560094],\n",
      "        [ 0.26551748],\n",
      "        [ 0.34150339],\n",
      "        [ 0.31681078],\n",
      "        [ 0.2478179 ],\n",
      "        [ 0.69410501],\n",
      "        [ 0.61691537],\n",
      "        [ 0.51292565],\n",
      "        [ 0.73880519],\n",
      "        [ 0.70546877],\n",
      "        [ 0.71110258],\n",
      "        [ 0.53995433],\n",
      "        [ 0.54659887],\n",
      "        [ 0.47096146],\n",
      "        [ 0.57917504],\n",
      "        [ 0.47807892],\n",
      "        [ 0.06191853],\n",
      "        [ 0.45657272],\n",
      "        [ 0.43459381],\n",
      "        [ 0.37350612],\n",
      "        [ 0.63526451],\n",
      "        [ 0.57917504],\n",
      "        [ 0.39685348],\n",
      "        [ 0.52653131]],\n",
      "\n",
      "       [[ 0.74481848],\n",
      "        [ 0.57905961],\n",
      "        [ 0.57424032],\n",
      "        [ 0.51708191],\n",
      "        [ 0.46457641],\n",
      "        [ 0.57665287],\n",
      "        [ 0.47530037],\n",
      "        [ 0.5693977 ],\n",
      "        [ 0.74685306],\n",
      "        [ 0.61679994],\n",
      "        [ 0.83437244],\n",
      "        [ 0.75495027],\n",
      "        [ 0.53231063],\n",
      "        [ 0.90621661],\n",
      "        [ 0.78474394],\n",
      "        [ 0.69470361],\n",
      "        [ 0.728391  ],\n",
      "        [ 0.85464963],\n",
      "        [ 0.63514907],\n",
      "        [ 0.55226141],\n",
      "        [ 0.79059761],\n",
      "        [ 0.6882589 ],\n",
      "        [ 0.74073684],\n",
      "        [ 0.71589084],\n",
      "        [ 0.8155749 ],\n",
      "        [ 0.77688535],\n",
      "        [ 0.9251013 ],\n",
      "        [ 0.72007494],\n",
      "        [ 0.67524353]],\n",
      "\n",
      "       [[ 0.36468309],\n",
      "        [ 0.40182733],\n",
      "        [ 0.56444843],\n",
      "        [ 0.5239367 ],\n",
      "        [ 0.59790452],\n",
      "        [ 0.51329919],\n",
      "        [ 0.55124525],\n",
      "        [ 0.60734921],\n",
      "        [ 0.40437113],\n",
      "        [ 0.54731368],\n",
      "        [ 0.5405529 ],\n",
      "        [ 0.65837958],\n",
      "        [ 0.48590878],\n",
      "        [ 0.64393328],\n",
      "        [ 0.68105406],\n",
      "        [ 0.67637775],\n",
      "        [ 0.70893961],\n",
      "        [ 0.66817598],\n",
      "        [ 0.60860897],\n",
      "        [ 0.6973283 ],\n",
      "        [ 0.60237184],\n",
      "        [ 0.53811081],\n",
      "        [ 0.58018315],\n",
      "        [ 0.60159029],\n",
      "        [ 0.42960096],\n",
      "        [ 0.60384361],\n",
      "        [ 0.75523976],\n",
      "        [ 0.67761558],\n",
      "        [ 0.69908348]],\n",
      "\n",
      "       [[ 0.16258539],\n",
      "        [ 0.3274538 ],\n",
      "        [ 0.51879663],\n",
      "        [ 0.59195614],\n",
      "        [ 0.54915198],\n",
      "        [ 0.29931698],\n",
      "        [ 0.74855145],\n",
      "        [ 0.40572517],\n",
      "        [ 0.44315688],\n",
      "        [ 0.51503416],\n",
      "        [ 0.40097637],\n",
      "        [ 0.56831819],\n",
      "        [ 0.41001816],\n",
      "        [ 0.63788346],\n",
      "        [ 0.67234624],\n",
      "        [ 0.58151111],\n",
      "        [ 0.60344914],\n",
      "        [ 0.59867612],\n",
      "        [ 0.60258232],\n",
      "        [ 0.59361927],\n",
      "        [ 0.66820876],\n",
      "        [ 0.70767617],\n",
      "        [ 0.48571836],\n",
      "        [ 0.51546167],\n",
      "        [ 0.31619435],\n",
      "        [ 0.38007899],\n",
      "        [ 0.81461459],\n",
      "        [ 0.64114218],\n",
      "        [ 0.55598223]],\n",
      "\n",
      "       [[-0.22865793],\n",
      "        [-0.3169612 ],\n",
      "        [-0.29045227],\n",
      "        [-0.31733963],\n",
      "        [-0.19964071],\n",
      "        [-0.22796541],\n",
      "        [-0.19728816],\n",
      "        [-0.16200008],\n",
      "        [-0.11176048],\n",
      "        [-0.16524578],\n",
      "        [-0.17866441],\n",
      "        [-0.23282316],\n",
      "        [-0.15072237],\n",
      "        [-0.12603757],\n",
      "        [-0.06922655],\n",
      "        [-0.04992206],\n",
      "        [-0.01995834],\n",
      "        [-0.07753027],\n",
      "        [-0.12572502],\n",
      "        [-0.16200008],\n",
      "        [-0.20470059],\n",
      "        [-0.17046092],\n",
      "        [-0.16589619],\n",
      "        [-0.10042284],\n",
      "        [-0.08981507],\n",
      "        [-0.08650431],\n",
      "        [-0.11484691],\n",
      "        [-0.08200723],\n",
      "        [-0.11732292]]]), '_i16': \"model.compile(Adam(), loss='mean_absolute_error')\\n\\nhistory = model.fit(encoder_input_data, decoder_target_data,\\n                    batch_size=batch_size,\\n                    epochs=epochs,\\n                    validation_split=0.20)\", 'history': <tensorflow.python.keras.callbacks.History object at 0x00000163405470C8>, '_i17': \"plt.plot(np.exp(history.history['loss']))\\nplt.plot(np.exp(history.history['val_loss']))\\n\\nplt.xlabel('Epoch')\\nplt.ylabel('Mean Absolute Error Loss')\\nplt.title('Loss Over Time')\\nplt.legend(['Train','Validation']);\", '_i18': 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,pred_steps,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', 'predict_sequence': <function predict_sequence at 0x0000016347D91C18>, '_i19': 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\nvf\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', '_i20': 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', '_i21': \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", 'predict_and_plot': <function predict_and_plot at 0x000001634EE2CEE8>, '_i22': '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', '_i23': 'def predict_sequence(input_sequence):\\n\\n    history_sequence = input_sequence.copy()\\n    pred_sequence = np.zeros((1,30,1)) # initialize output (pred_steps time steps)  \\n    \\n    for i in range(pred_steps):\\n        \\n        # record next time step prediction (last time step of model output) \\n        last_step_pred = model.predict(history_sequence)[0,-1,0]\\n        pred_sequence[0,i,0] = last_step_pred\\n        \\n        # add the next time step prediction to the history sequence\\n        history_sequence = np.concatenate([history_sequence, \\n                                           last_step_pred.reshape(-1,1,1)], axis=1)\\n\\n    return pred_sequence', '_i24': 'encoder_input_data = get_time_block_series(series_array, date_to_index, val_enc_start, val_enc_end)\\nencoder_input_data, encode_series_mean = transform_series_encode(encoder_input_data)\\ndecoder_target_data = get_time_block_series(series_array, date_to_index, val_pred_start, val_pred_end)\\ndecoder_target_data = transform_series_decode(decoder_target_data, encode_series_mean)', '_i25': \"def predict_and_plot(encoder_input_data, decoder_target_data, sample_ind, enc_tail_len=50):\\n\\n    encode_series = encoder_input_data[sample_ind:sample_ind+1,:,:] \\n    pred_series = predict_sequence(encode_series)\\n    \\n    encode_series = encode_series.reshape(-1,1)\\n    pred_series = pred_series.reshape(-1,1)  \\n    target_series = decoder_target_data[sample_ind,:,:].reshape(-1,1)\\n    \\n    encode_series_tail = np.concatenate([encode_series[-enc_tail_len:],target_series[:1]])\\n    x_encode = encode_series_tail.shape[0]\\n    \\n    #plt.figure(figsize=(10,6))   \\n\\n    plt.plot(range(1,x_encode+1),encode_series_tail)\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),target_series,color='green')\\n    plt.plot(range(x_encode,x_encode+pred_steps-31),pred_series[:69],color='red',linestyle='--')\\n    \\n    plt.title('Encoder Series Tail of Length %d, Target Series, and Predictions' % enc_tail_len)\\n    plt.legend(['Encoding Series','Target Series','Predictions'])\", '_i26': '# sp500 prediction\\npredict_and_plot(encoder_input_data, decoder_target_data, \\n                 sample_ind=0, enc_tail_len=10)', '_i27': '%debug'}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "ipdb>  exit\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
